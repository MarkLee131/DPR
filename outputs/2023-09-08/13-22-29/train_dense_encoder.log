[2023-09-08 13:22:29,393][root][INFO] - CFG's local_rank=2
[2023-09-08 13:22:29,394][root][INFO] - CFG's local_rank=1
[2023-09-08 13:22:29,395][root][INFO] - Env WORLD_SIZE=4
[2023-09-08 13:22:29,395][root][INFO] - Env WORLD_SIZE=4
[2023-09-08 13:22:29,442][root][INFO] - CFG's local_rank=0
[2023-09-08 13:22:29,443][root][INFO] - Env WORLD_SIZE=4
[2023-09-08 13:22:29,515][root][INFO] - CFG's local_rank=3
[2023-09-08 13:22:29,516][root][INFO] - Env WORLD_SIZE=4
[2023-09-08 13:22:33,032][root][INFO] - Initialized host kaixuan_cuda11-U2141 as d.rank 0 on device=cuda:0, n_gpu=1, world size=4
[2023-09-08 13:22:33,032][root][INFO] - Initialized host kaixuan_cuda11-U2141 as d.rank 1 on device=cuda:1, n_gpu=1, world size=4
[2023-09-08 13:22:33,032][root][INFO] - Initialized host kaixuan_cuda11-U2141 as d.rank 3 on device=cuda:3, n_gpu=1, world size=4
[2023-09-08 13:22:33,033][root][INFO] - Initialized host kaixuan_cuda11-U2141 as d.rank 2 on device=cuda:2, n_gpu=1, world size=4
[2023-09-08 13:22:33,033][root][INFO] - 16-bits training: False 
[2023-09-08 13:22:33,033][root][INFO] - 16-bits training: False 
[2023-09-08 13:22:33,033][root][INFO] - 16-bits training: False 
[2023-09-08 13:22:33,034][root][INFO] - CFG (after gpu  configuration):
[2023-09-08 13:22:33,034][root][INFO] - ***** Initializing components for training *****
[2023-09-08 13:22:33,035][root][INFO] - ***** Initializing components for training *****
[2023-09-08 13:22:33,035][root][INFO] - Checkpoint files []
[2023-09-08 13:22:33,034][root][INFO] - 16-bits training: False 
[2023-09-08 13:22:33,036][root][INFO] - Checkpoint files []
[2023-09-08 13:22:33,036][root][INFO] - ***** Initializing components for training *****
[2023-09-08 13:22:33,037][root][INFO] - Checkpoint files []
[2023-09-08 13:22:33,045][root][INFO] - encoder:
  encoder_model_type: hf_bert
  pretrained_model_cfg: bert-base-uncased
  pretrained_file: null
  projection_dim: 0
  sequence_length: 256
  dropout: 0.1
  fix_ctx_encoder: false
  pretrained: true
train:
  batch_size: 4
  dev_batch_size: 4
  adam_eps: 1.0e-08
  adam_betas: (0.9, 0.999)
  max_grad_norm: 2.0
  log_batch_step: 10
  train_rolling_loss_step: 100
  weight_decay: 0.0
  learning_rate: 2.0e-05
  warmup_steps: 1237
  gradient_accumulation_steps: 1
  num_train_epochs: 40
  eval_per_epoch: 1
  hard_negatives: 1
  other_negatives: 0
  val_av_rank_hard_neg: 30
  val_av_rank_other_neg: 30
  val_av_rank_bsz: 128
  val_av_rank_max_qs: 10000
datasets:
  nq_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-train
  nq_train_hn1:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-adv-hn-train
  nq_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.nq-dev
  trivia_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.trivia-train
  trivia_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.trivia-dev
  squad1_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.squad1-train
  squad1_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.squad1-dev
  webq_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.webq-train
  webq_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.webq-dev
  curatedtrec_train:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.curatedtrec-train
  curatedtrec_dev:
    _target_: dpr.data.biencoder_data.JsonQADataset
    file: data.retriever.curatedtrec-dev
train_datasets:
- nq_train
dev_datasets:
- nq_dev
output_dir: ./output_test
train_sampling_rates: null
loss_scale_factors: null
do_lower_case: true
val_av_rank_start_epoch: 30
seed: 12345
checkpoint_file_name: dpr_biencoder
model_file: null
local_rank: 0
global_loss_buf_sz: 592000
device: cuda:0
distributed_world_size: 4
distributed_port: null
distributed_init_method: null
no_cuda: false
n_gpu: 1
fp16: false
fp16_opt_level: O1
special_tokens: null
ignore_checkpoint_offset: false
ignore_checkpoint_optimizer: false
ignore_checkpoint_lr: false
multi_q_encoder: false
local_shards_dataloader: false

[2023-09-08 13:22:33,045][root][INFO] - ***** Initializing components for training *****
[2023-09-08 13:22:33,046][root][INFO] - Checkpoint files []
[2023-09-08 13:22:33,212][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2023-09-08 13:22:33,212][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2023-09-08 13:22:33,214][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2023-09-08 13:22:33,222][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2023-09-08 13:22:35,882][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2023-09-08 13:22:35,967][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2023-09-08 13:22:36,308][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2023-09-08 13:22:36,471][dpr.models.hf_models][INFO] - Initializing HF BERT Encoder. cfg_name=bert-base-uncased
[2023-09-08 13:22:41,583][dpr.utils.conf_utils][INFO] - train_datasets: ['nq_train']
[2023-09-08 13:22:41,584][dpr.utils.conf_utils][INFO] - train_datasets: ['nq_train']
[2023-09-08 13:22:41,584][dpr.utils.conf_utils][INFO] - train_datasets: ['nq_train']
[2023-09-08 13:22:41,584][dpr.utils.conf_utils][INFO] - train_datasets: ['nq_train']
[2023-09-08 13:22:41,587][dpr.utils.conf_utils][INFO] - dev_datasets: ['nq_dev']
[2023-09-08 13:22:41,588][dpr.utils.conf_utils][INFO] - dev_datasets: ['nq_dev']
[2023-09-08 13:22:41,588][dpr.utils.conf_utils][INFO] - dev_datasets: ['nq_dev']
[2023-09-08 13:22:41,588][dpr.utils.conf_utils][INFO] - dev_datasets: ['nq_dev']
[2023-09-08 13:22:41,589][root][INFO] - Initializing task/set data ['nq_train']
[2023-09-08 13:22:41,589][root][INFO] - Calculating shard positions
[2023-09-08 13:22:41,589][dpr.data.biencoder_data][INFO] - Loading all data
[2023-09-08 13:22:41,589][root][INFO] - Initializing task/set data ['nq_train']
[2023-09-08 13:22:41,589][root][INFO] - Calculating shard positions
[2023-09-08 13:22:41,590][dpr.data.biencoder_data][INFO] - Loading all data
[2023-09-08 13:22:41,590][root][INFO] - Initializing task/set data ['nq_train']
[2023-09-08 13:22:41,590][root][INFO] - Calculating shard positions
[2023-09-08 13:22:41,590][root][INFO] - Initializing task/set data ['nq_train']
[2023-09-08 13:22:41,590][dpr.data.biencoder_data][INFO] - Loading all data
[2023-09-08 13:22:41,590][root][INFO] - Calculating shard positions
[2023-09-08 13:22:41,590][dpr.data.biencoder_data][INFO] - Loading all data
[2023-09-08 13:22:41,591][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz
[2023-09-08 13:22:41,591][dpr.data.download_data][INFO] - Download root_dir /mnt/local/Baselines_Bugs/DPR
[2023-09-08 13:22:41,591][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Download root_dir /mnt/local/Baselines_Bugs/DPR
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - File to be downloaded as /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - File to be downloaded as /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Requested resource from https://dl.fbaipublicfiles.com/dpr/data/retriever/biencoder-nq-train.json.gz
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Download root_dir /mnt/local/Baselines_Bugs/DPR
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Download root_dir /mnt/local/Baselines_Bugs/DPR
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/LICENSE
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/LICENSE
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - File to be downloaded as /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2023-09-08 13:22:41,592][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File to be downloaded as /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/README
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/LICENSE
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/README
[2023-09-08 13:22:41,593][dpr.data.biencoder_data][INFO] - Data files: ['/mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json']
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2023-09-08 13:22:41,593][dpr.data.biencoder_data][INFO] - Data files: ['/mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json']
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/README
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/LICENSE
[2023-09-08 13:22:41,593][dpr.data.biencoder_data][INFO] - Data files: ['/mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json']
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/LICENSE
[2023-09-08 13:22:41,593][root][INFO] - Reading file /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - Loading from https://dl.fbaipublicfiles.com/dpr/nq_license/README
[2023-09-08 13:22:41,593][root][INFO] - Reading file /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,593][dpr.data.download_data][INFO] - File already exist /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/README
[2023-09-08 13:22:41,594][dpr.data.biencoder_data][INFO] - Data files: ['/mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json']
[2023-09-08 13:22:41,594][root][INFO] - Reading file /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:22:41,594][root][INFO] - Reading file /mnt/local/Baselines_Bugs/DPR/downloads/data/retriever/nq-train.json
[2023-09-08 13:23:36,885][root][INFO] - Aggregated data size: 58880
[2023-09-08 13:23:36,915][dpr.data.biencoder_data][INFO] - Total cleaned data size: 58880
[2023-09-08 13:23:36,917][root][INFO] - samples_per_shard=14720, shard_start_idx=14720, shard_end_idx=29440, max_iterations=3680
[2023-09-08 13:23:36,917][root][INFO] - Sharded dataset data 58880
[2023-09-08 13:23:36,917][root][INFO] - rank=1; Multi set data sizes [58880]
[2023-09-08 13:23:36,917][root][INFO] - rank=1; Multi set total data 58880
[2023-09-08 13:23:36,918][root][INFO] - rank=1; Multi set sampling_rates None
[2023-09-08 13:23:36,918][root][INFO] - rank=1; Multi set max_iterations per dataset [3680]
[2023-09-08 13:23:36,918][root][INFO] - rank=1; Multi set max_iterations 3680
[2023-09-08 13:23:36,918][root][INFO] -   Total iterations per epoch=3680
[2023-09-08 13:23:36,918][root][INFO] -  Total updates=147200
[2023-09-08 13:23:36,918][root][INFO] -   Eval step = 3680
[2023-09-08 13:23:36,919][root][INFO] - ***** Training *****
[2023-09-08 13:23:36,919][root][INFO] - ***** Epoch 0 *****
[2023-09-08 13:23:36,921][root][INFO] - rank=1; Iteration start
[2023-09-08 13:23:36,921][root][INFO] - rank=1; Multi set iteration: iteration ptr per set: [0]
[2023-09-08 13:23:36,921][root][INFO] - rank=1; Multi set iteration: source 0, batches to be taken: 3680
[2023-09-08 13:23:36,924][root][INFO] - rank=1; data_src_indices len=3680
[2023-09-08 13:23:39,713][root][INFO] - Aggregated data size: 58880
[2023-09-08 13:23:39,744][dpr.data.biencoder_data][INFO] - Total cleaned data size: 58880
[2023-09-08 13:23:39,745][root][INFO] - samples_per_shard=14720, shard_start_idx=0, shard_end_idx=14720, max_iterations=3680
[2023-09-08 13:23:39,745][root][INFO] - Sharded dataset data 58880
[2023-09-08 13:23:39,746][root][INFO] - rank=0; Multi set data sizes [58880]
[2023-09-08 13:23:39,746][root][INFO] - rank=0; Multi set total data 58880
[2023-09-08 13:23:39,746][root][INFO] - rank=0; Multi set sampling_rates None
[2023-09-08 13:23:39,746][root][INFO] - rank=0; Multi set max_iterations per dataset [3680]
[2023-09-08 13:23:39,746][root][INFO] - rank=0; Multi set max_iterations 3680
[2023-09-08 13:23:39,746][root][INFO] -   Total iterations per epoch=3680
[2023-09-08 13:23:39,746][root][INFO] -  Total updates=147200
[2023-09-08 13:23:39,747][root][INFO] -   Eval step = 3680
[2023-09-08 13:23:39,747][root][INFO] - ***** Training *****
[2023-09-08 13:23:39,747][root][INFO] - ***** Epoch 0 *****
[2023-09-08 13:23:39,749][root][INFO] - rank=0; Iteration start
[2023-09-08 13:23:39,749][root][INFO] - rank=0; Multi set iteration: iteration ptr per set: [0]
[2023-09-08 13:23:39,749][root][INFO] - rank=0; Multi set iteration: source 0, batches to be taken: 3680
[2023-09-08 13:23:39,753][root][INFO] - rank=0; data_src_indices len=3680
[2023-09-08 13:23:40,148][root][INFO] - Aggregated data size: 58880
[2023-09-08 13:23:40,180][dpr.data.biencoder_data][INFO] - Total cleaned data size: 58880
[2023-09-08 13:23:40,183][root][INFO] - samples_per_shard=14720, shard_start_idx=44160, shard_end_idx=58880, max_iterations=3680
[2023-09-08 13:23:40,183][root][INFO] - Sharded dataset data 58880
[2023-09-08 13:23:40,183][root][INFO] - rank=3; Multi set data sizes [58880]
[2023-09-08 13:23:40,183][root][INFO] - Aggregated data size: 58880
[2023-09-08 13:23:40,183][root][INFO] - rank=3; Multi set total data 58880
[2023-09-08 13:23:40,183][root][INFO] - rank=3; Multi set sampling_rates None
[2023-09-08 13:23:40,183][root][INFO] - rank=3; Multi set max_iterations per dataset [3680]
[2023-09-08 13:23:40,183][root][INFO] - rank=3; Multi set max_iterations 3680
[2023-09-08 13:23:40,184][root][INFO] -   Total iterations per epoch=3680
[2023-09-08 13:23:40,184][root][INFO] -  Total updates=147200
[2023-09-08 13:23:40,184][root][INFO] -   Eval step = 3680
[2023-09-08 13:23:40,184][root][INFO] - ***** Training *****
[2023-09-08 13:23:40,184][root][INFO] - ***** Epoch 0 *****
[2023-09-08 13:23:40,187][root][INFO] - rank=3; Iteration start
[2023-09-08 13:23:40,187][root][INFO] - rank=3; Multi set iteration: iteration ptr per set: [0]
[2023-09-08 13:23:40,187][root][INFO] - rank=3; Multi set iteration: source 0, batches to be taken: 3680
[2023-09-08 13:23:40,190][root][INFO] - rank=3; data_src_indices len=3680
[2023-09-08 13:23:40,215][dpr.data.biencoder_data][INFO] - Total cleaned data size: 58880
[2023-09-08 13:23:40,217][root][INFO] - samples_per_shard=14720, shard_start_idx=29440, shard_end_idx=44160, max_iterations=3680
[2023-09-08 13:23:40,217][root][INFO] - Sharded dataset data 58880
[2023-09-08 13:23:40,217][root][INFO] - rank=2; Multi set data sizes [58880]
[2023-09-08 13:23:40,217][root][INFO] - rank=2; Multi set total data 58880
[2023-09-08 13:23:40,217][root][INFO] - rank=2; Multi set sampling_rates None
[2023-09-08 13:23:40,218][root][INFO] - rank=2; Multi set max_iterations per dataset [3680]
[2023-09-08 13:23:40,218][root][INFO] - rank=2; Multi set max_iterations 3680
[2023-09-08 13:23:40,218][root][INFO] -   Total iterations per epoch=3680
[2023-09-08 13:23:40,218][root][INFO] -  Total updates=147200
[2023-09-08 13:23:40,219][root][INFO] -   Eval step = 3680
[2023-09-08 13:23:40,219][root][INFO] - ***** Training *****
[2023-09-08 13:23:40,219][root][INFO] - ***** Epoch 0 *****
[2023-09-08 13:23:40,221][root][INFO] - rank=2; Iteration start
[2023-09-08 13:23:40,221][root][INFO] - rank=2; Multi set iteration: iteration ptr per set: [0]
[2023-09-08 13:23:40,221][root][INFO] - rank=2; Multi set iteration: source 0, batches to be taken: 3680
[2023-09-08 13:23:40,224][root][INFO] - rank=2; data_src_indices len=3680
[2023-09-08 13:23:41,896][root][INFO] - Epoch: 0: Step: 1/3680, loss=27.282068, lr=0.000000
[2023-09-08 13:23:41,897][root][INFO] - Epoch: 0: Step: 1/3680, loss=27.282068, lr=0.000000
[2023-09-08 13:23:41,898][root][INFO] - Epoch: 0: Step: 1/3680, loss=27.282068, lr=0.000000
[2023-09-08 13:23:41,923][root][INFO] - Epoch: 0: Step: 1/3680, loss=27.282068, lr=0.000000
[2023-09-08 13:23:49,144][root][INFO] - Epoch: 0: Step: 11/3680, loss=33.794693, lr=0.000000
[2023-09-08 13:23:49,144][root][INFO] - Epoch: 0: Step: 11/3680, loss=33.794693, lr=0.000000
[2023-09-08 13:23:49,144][root][INFO] - Epoch: 0: Step: 11/3680, loss=33.794693, lr=0.000000
[2023-09-08 13:23:49,146][root][INFO] - Epoch: 0: Step: 11/3680, loss=33.794693, lr=0.000000
[2023-09-08 13:23:56,207][root][INFO] - Epoch: 0: Step: 21/3680, loss=28.126881, lr=0.000000
[2023-09-08 13:23:56,211][root][INFO] - Epoch: 0: Step: 21/3680, loss=28.126881, lr=0.000000
[2023-09-08 13:23:56,211][root][INFO] - Epoch: 0: Step: 21/3680, loss=28.126881, lr=0.000000
[2023-09-08 13:23:56,212][root][INFO] - Epoch: 0: Step: 21/3680, loss=28.126881, lr=0.000000
[2023-09-08 13:24:03,404][root][INFO] - Epoch: 0: Step: 31/3680, loss=18.235239, lr=0.000001
[2023-09-08 13:24:03,405][root][INFO] - Epoch: 0: Step: 31/3680, loss=18.235239, lr=0.000001
[2023-09-08 13:24:03,406][root][INFO] - Epoch: 0: Step: 31/3680, loss=18.235239, lr=0.000001
[2023-09-08 13:24:03,406][root][INFO] - Epoch: 0: Step: 31/3680, loss=18.235239, lr=0.000001
[2023-09-08 13:24:10,478][root][INFO] - Epoch: 0: Step: 41/3680, loss=5.452792, lr=0.000001
[2023-09-08 13:24:10,478][root][INFO] - Epoch: 0: Step: 41/3680, loss=5.452792, lr=0.000001
[2023-09-08 13:24:10,478][root][INFO] - Epoch: 0: Step: 41/3680, loss=5.452792, lr=0.000001
[2023-09-08 13:24:10,480][root][INFO] - Epoch: 0: Step: 41/3680, loss=5.452792, lr=0.000001
[2023-09-08 13:24:17,543][root][INFO] - Epoch: 0: Step: 51/3680, loss=14.161546, lr=0.000001
[2023-09-08 13:24:17,544][root][INFO] - Epoch: 0: Step: 51/3680, loss=14.161546, lr=0.000001
[2023-09-08 13:24:17,544][root][INFO] - Epoch: 0: Step: 51/3680, loss=14.161546, lr=0.000001
[2023-09-08 13:24:17,544][root][INFO] - Epoch: 0: Step: 51/3680, loss=14.161546, lr=0.000001
[2023-09-08 13:24:24,676][root][INFO] - Epoch: 0: Step: 61/3680, loss=7.579708, lr=0.000001
[2023-09-08 13:24:24,680][root][INFO] - Epoch: 0: Step: 61/3680, loss=7.579708, lr=0.000001
[2023-09-08 13:24:24,683][root][INFO] - Epoch: 0: Step: 61/3680, loss=7.579708, lr=0.000001
[2023-09-08 13:24:24,734][root][INFO] - Epoch: 0: Step: 61/3680, loss=7.579708, lr=0.000001
[2023-09-08 13:24:32,037][root][INFO] - Epoch: 0: Step: 71/3680, loss=3.485435, lr=0.000001
[2023-09-08 13:24:32,044][root][INFO] - Epoch: 0: Step: 71/3680, loss=3.485435, lr=0.000001
[2023-09-08 13:24:32,045][root][INFO] - Epoch: 0: Step: 71/3680, loss=3.485435, lr=0.000001
[2023-09-08 13:24:32,060][root][INFO] - Epoch: 0: Step: 71/3680, loss=3.485435, lr=0.000001
[2023-09-08 13:24:39,168][root][INFO] - Epoch: 0: Step: 81/3680, loss=7.167857, lr=0.000001
[2023-09-08 13:24:39,169][root][INFO] - Epoch: 0: Step: 81/3680, loss=7.167857, lr=0.000001
[2023-09-08 13:24:39,174][root][INFO] - Epoch: 0: Step: 81/3680, loss=7.167857, lr=0.000001
[2023-09-08 13:24:39,175][root][INFO] - Epoch: 0: Step: 81/3680, loss=7.167857, lr=0.000001
[2023-09-08 13:24:46,210][root][INFO] - Epoch: 0: Step: 91/3680, loss=6.940288, lr=0.000001
[2023-09-08 13:24:46,214][root][INFO] - Epoch: 0: Step: 91/3680, loss=6.940288, lr=0.000001
[2023-09-08 13:24:46,217][root][INFO] - Epoch: 0: Step: 91/3680, loss=6.940288, lr=0.000001
[2023-09-08 13:24:46,218][root][INFO] - Epoch: 0: Step: 91/3680, loss=6.940288, lr=0.000001
[2023-09-08 13:24:52,549][root][INFO] - Train batch 100
[2023-09-08 13:24:52,550][root][INFO] - Avg. loss per last 100 batches: 12.912789
[2023-09-08 13:24:52,555][root][INFO] - Train batch 100
[2023-09-08 13:24:52,556][root][INFO] - Avg. loss per last 100 batches: 12.912789
[2023-09-08 13:24:52,560][root][INFO] - Train batch 100
[2023-09-08 13:24:52,560][root][INFO] - Avg. loss per last 100 batches: 12.912789
[2023-09-08 13:24:52,575][root][INFO] - Train batch 100
[2023-09-08 13:24:52,575][root][INFO] - Avg. loss per last 100 batches: 12.912789
[2023-09-08 13:24:53,290][root][INFO] - Epoch: 0: Step: 101/3680, loss=1.893810, lr=0.000002
[2023-09-08 13:24:53,291][root][INFO] - Epoch: 0: Step: 101/3680, loss=1.893810, lr=0.000002
[2023-09-08 13:24:53,291][root][INFO] - Epoch: 0: Step: 101/3680, loss=1.893810, lr=0.000002
[2023-09-08 13:24:53,292][root][INFO] - Epoch: 0: Step: 101/3680, loss=1.893810, lr=0.000002
[2023-09-08 13:25:00,435][root][INFO] - Epoch: 0: Step: 111/3680, loss=3.888396, lr=0.000002
[2023-09-08 13:25:00,442][root][INFO] - Epoch: 0: Step: 111/3680, loss=3.888396, lr=0.000002
[2023-09-08 13:25:00,443][root][INFO] - Epoch: 0: Step: 111/3680, loss=3.888396, lr=0.000002
[2023-09-08 13:25:00,443][root][INFO] - Epoch: 0: Step: 111/3680, loss=3.888396, lr=0.000002
[2023-09-08 13:25:07,499][root][INFO] - Epoch: 0: Step: 121/3680, loss=4.454903, lr=0.000002
[2023-09-08 13:25:07,502][root][INFO] - Epoch: 0: Step: 121/3680, loss=4.454903, lr=0.000002
[2023-09-08 13:25:07,505][root][INFO] - Epoch: 0: Step: 121/3680, loss=4.454903, lr=0.000002
[2023-09-08 13:25:07,507][root][INFO] - Epoch: 0: Step: 121/3680, loss=4.454903, lr=0.000002
[2023-09-08 13:25:14,570][root][INFO] - Epoch: 0: Step: 131/3680, loss=2.796670, lr=0.000002
[2023-09-08 13:25:14,574][root][INFO] - Epoch: 0: Step: 131/3680, loss=2.796670, lr=0.000002
[2023-09-08 13:25:14,576][root][INFO] - Epoch: 0: Step: 131/3680, loss=2.796670, lr=0.000002
[2023-09-08 13:25:14,579][root][INFO] - Epoch: 0: Step: 131/3680, loss=2.796670, lr=0.000002
[2023-09-08 13:25:21,675][root][INFO] - Epoch: 0: Step: 141/3680, loss=4.576873, lr=0.000002
[2023-09-08 13:25:21,677][root][INFO] - Epoch: 0: Step: 141/3680, loss=4.576873, lr=0.000002
[2023-09-08 13:25:21,680][root][INFO] - Epoch: 0: Step: 141/3680, loss=4.576873, lr=0.000002
[2023-09-08 13:25:21,683][root][INFO] - Epoch: 0: Step: 141/3680, loss=4.576873, lr=0.000002
[2023-09-08 13:25:28,788][root][INFO] - Epoch: 0: Step: 151/3680, loss=2.366190, lr=0.000002
[2023-09-08 13:25:28,789][root][INFO] - Epoch: 0: Step: 151/3680, loss=2.366190, lr=0.000002
[2023-09-08 13:25:28,793][root][INFO] - Epoch: 0: Step: 151/3680, loss=2.366190, lr=0.000002
[2023-09-08 13:25:28,793][root][INFO] - Epoch: 0: Step: 151/3680, loss=2.366190, lr=0.000002
[2023-09-08 13:25:35,939][root][INFO] - Epoch: 0: Step: 161/3680, loss=2.104194, lr=0.000003
[2023-09-08 13:25:35,940][root][INFO] - Epoch: 0: Step: 161/3680, loss=2.104194, lr=0.000003
[2023-09-08 13:25:35,941][root][INFO] - Epoch: 0: Step: 161/3680, loss=2.104194, lr=0.000003
[2023-09-08 13:25:35,963][root][INFO] - Epoch: 0: Step: 161/3680, loss=2.104194, lr=0.000003
[2023-09-08 13:25:43,394][root][INFO] - Epoch: 0: Step: 171/3680, loss=2.477541, lr=0.000003
[2023-09-08 13:25:43,394][root][INFO] - Epoch: 0: Step: 171/3680, loss=2.477541, lr=0.000003
[2023-09-08 13:25:43,399][root][INFO] - Epoch: 0: Step: 171/3680, loss=2.477541, lr=0.000003
[2023-09-08 13:25:43,434][root][INFO] - Epoch: 0: Step: 171/3680, loss=2.477541, lr=0.000003
[2023-09-08 13:25:50,784][root][INFO] - Epoch: 0: Step: 181/3680, loss=4.448198, lr=0.000003
[2023-09-08 13:25:50,787][root][INFO] - Epoch: 0: Step: 181/3680, loss=4.448198, lr=0.000003
[2023-09-08 13:25:50,790][root][INFO] - Epoch: 0: Step: 181/3680, loss=4.448198, lr=0.000003
[2023-09-08 13:25:50,808][root][INFO] - Epoch: 0: Step: 181/3680, loss=4.448198, lr=0.000003
[2023-09-08 13:25:57,931][root][INFO] - Epoch: 0: Step: 191/3680, loss=4.587168, lr=0.000003
[2023-09-08 13:25:57,931][root][INFO] - Epoch: 0: Step: 191/3680, loss=4.587168, lr=0.000003
[2023-09-08 13:25:57,932][root][INFO] - Epoch: 0: Step: 191/3680, loss=4.587168, lr=0.000003
[2023-09-08 13:25:57,934][root][INFO] - Epoch: 0: Step: 191/3680, loss=4.587168, lr=0.000003
[2023-09-08 13:26:04,317][root][INFO] - Train batch 200
[2023-09-08 13:26:04,318][root][INFO] - Avg. loss per last 100 batches: 3.297070
[2023-09-08 13:26:04,319][root][INFO] - Train batch 200
[2023-09-08 13:26:04,319][root][INFO] - Avg. loss per last 100 batches: 3.297070
[2023-09-08 13:26:04,323][root][INFO] - Train batch 200
[2023-09-08 13:26:04,324][root][INFO] - Avg. loss per last 100 batches: 3.297070
[2023-09-08 13:26:04,334][root][INFO] - Train batch 200
[2023-09-08 13:26:04,334][root][INFO] - Avg. loss per last 100 batches: 3.297070
[2023-09-08 13:26:05,054][root][INFO] - Epoch: 0: Step: 201/3680, loss=0.366686, lr=0.000003
[2023-09-08 13:26:05,055][root][INFO] - Epoch: 0: Step: 201/3680, loss=0.366686, lr=0.000003
[2023-09-08 13:26:05,058][root][INFO] - Epoch: 0: Step: 201/3680, loss=0.366686, lr=0.000003
[2023-09-08 13:26:05,073][root][INFO] - Epoch: 0: Step: 201/3680, loss=0.366686, lr=0.000003
[2023-09-08 13:26:12,242][root][INFO] - Epoch: 0: Step: 211/3680, loss=1.857668, lr=0.000003
[2023-09-08 13:26:12,242][root][INFO] - Epoch: 0: Step: 211/3680, loss=1.857668, lr=0.000003
[2023-09-08 13:26:12,243][root][INFO] - Epoch: 0: Step: 211/3680, loss=1.857668, lr=0.000003
[2023-09-08 13:26:12,244][root][INFO] - Epoch: 0: Step: 211/3680, loss=1.857668, lr=0.000003
[2023-09-08 13:26:19,333][root][INFO] - Epoch: 0: Step: 221/3680, loss=1.856814, lr=0.000004
[2023-09-08 13:26:19,334][root][INFO] - Epoch: 0: Step: 221/3680, loss=1.856814, lr=0.000004
[2023-09-08 13:26:19,335][root][INFO] - Epoch: 0: Step: 221/3680, loss=1.856814, lr=0.000004
[2023-09-08 13:26:19,336][root][INFO] - Epoch: 0: Step: 221/3680, loss=1.856814, lr=0.000004
[2023-09-08 13:26:26,491][root][INFO] - Epoch: 0: Step: 231/3680, loss=0.823970, lr=0.000004
[2023-09-08 13:26:26,491][root][INFO] - Epoch: 0: Step: 231/3680, loss=0.823970, lr=0.000004
[2023-09-08 13:26:26,493][root][INFO] - Epoch: 0: Step: 231/3680, loss=0.823970, lr=0.000004
[2023-09-08 13:26:26,509][root][INFO] - Epoch: 0: Step: 231/3680, loss=0.823970, lr=0.000004
[2023-09-08 13:26:33,682][root][INFO] - Epoch: 0: Step: 241/3680, loss=1.824322, lr=0.000004
[2023-09-08 13:26:33,684][root][INFO] - Epoch: 0: Step: 241/3680, loss=1.824322, lr=0.000004
[2023-09-08 13:26:33,686][root][INFO] - Epoch: 0: Step: 241/3680, loss=1.824322, lr=0.000004
[2023-09-08 13:26:33,687][root][INFO] - Epoch: 0: Step: 241/3680, loss=1.824322, lr=0.000004
[2023-09-08 13:26:40,793][root][INFO] - Epoch: 0: Step: 251/3680, loss=2.043157, lr=0.000004
[2023-09-08 13:26:40,795][root][INFO] - Epoch: 0: Step: 251/3680, loss=2.043157, lr=0.000004
[2023-09-08 13:26:40,796][root][INFO] - Epoch: 0: Step: 251/3680, loss=2.043157, lr=0.000004
[2023-09-08 13:26:40,818][root][INFO] - Epoch: 0: Step: 251/3680, loss=2.043157, lr=0.000004
[2023-09-08 13:26:47,911][root][INFO] - Epoch: 0: Step: 261/3680, loss=1.744152, lr=0.000004
[2023-09-08 13:26:47,911][root][INFO] - Epoch: 0: Step: 261/3680, loss=1.744152, lr=0.000004
[2023-09-08 13:26:47,912][root][INFO] - Epoch: 0: Step: 261/3680, loss=1.744152, lr=0.000004
[2023-09-08 13:26:47,915][root][INFO] - Epoch: 0: Step: 261/3680, loss=1.744152, lr=0.000004
[2023-09-08 13:26:55,056][root][INFO] - Epoch: 0: Step: 271/3680, loss=0.367280, lr=0.000004
[2023-09-08 13:26:55,056][root][INFO] - Epoch: 0: Step: 271/3680, loss=0.367280, lr=0.000004
[2023-09-08 13:26:55,057][root][INFO] - Epoch: 0: Step: 271/3680, loss=0.367280, lr=0.000004
[2023-09-08 13:26:55,058][root][INFO] - Epoch: 0: Step: 271/3680, loss=0.367280, lr=0.000004
[2023-09-08 13:27:02,195][root][INFO] - Epoch: 0: Step: 281/3680, loss=1.179628, lr=0.000005
[2023-09-08 13:27:02,198][root][INFO] - Epoch: 0: Step: 281/3680, loss=1.179628, lr=0.000005
[2023-09-08 13:27:02,200][root][INFO] - Epoch: 0: Step: 281/3680, loss=1.179628, lr=0.000005
[2023-09-08 13:27:02,200][root][INFO] - Epoch: 0: Step: 281/3680, loss=1.179628, lr=0.000005
[2023-09-08 13:27:09,330][root][INFO] - Epoch: 0: Step: 291/3680, loss=2.079678, lr=0.000005
[2023-09-08 13:27:09,332][root][INFO] - Epoch: 0: Step: 291/3680, loss=2.079678, lr=0.000005
[2023-09-08 13:27:09,332][root][INFO] - Epoch: 0: Step: 291/3680, loss=2.079678, lr=0.000005
[2023-09-08 13:27:09,334][root][INFO] - Epoch: 0: Step: 291/3680, loss=2.079678, lr=0.000005
[2023-09-08 13:27:15,766][root][INFO] - Train batch 300
[2023-09-08 13:27:15,766][root][INFO] - Avg. loss per last 100 batches: 1.664359
[2023-09-08 13:27:15,766][root][INFO] - Train batch 300
[2023-09-08 13:27:15,767][root][INFO] - Avg. loss per last 100 batches: 1.664359
[2023-09-08 13:27:15,769][root][INFO] - Train batch 300
[2023-09-08 13:27:15,769][root][INFO] - Avg. loss per last 100 batches: 1.664359
[2023-09-08 13:27:15,777][root][INFO] - Train batch 300
[2023-09-08 13:27:15,778][root][INFO] - Avg. loss per last 100 batches: 1.664359
[2023-09-08 13:27:16,487][root][INFO] - Epoch: 0: Step: 301/3680, loss=1.339948, lr=0.000005
[2023-09-08 13:27:16,488][root][INFO] - Epoch: 0: Step: 301/3680, loss=1.339948, lr=0.000005
[2023-09-08 13:27:16,490][root][INFO] - Epoch: 0: Step: 301/3680, loss=1.339948, lr=0.000005
[2023-09-08 13:27:16,490][root][INFO] - Epoch: 0: Step: 301/3680, loss=1.339948, lr=0.000005
[2023-09-08 13:27:23,748][root][INFO] - Epoch: 0: Step: 311/3680, loss=0.995783, lr=0.000005
[2023-09-08 13:27:23,755][root][INFO] - Epoch: 0: Step: 311/3680, loss=0.995783, lr=0.000005
[2023-09-08 13:27:23,756][root][INFO] - Epoch: 0: Step: 311/3680, loss=0.995783, lr=0.000005
[2023-09-08 13:27:23,756][root][INFO] - Epoch: 0: Step: 311/3680, loss=0.995783, lr=0.000005
[2023-09-08 13:27:30,834][root][INFO] - Epoch: 0: Step: 321/3680, loss=0.385961, lr=0.000005
[2023-09-08 13:27:30,835][root][INFO] - Epoch: 0: Step: 321/3680, loss=0.385961, lr=0.000005
[2023-09-08 13:27:30,835][root][INFO] - Epoch: 0: Step: 321/3680, loss=0.385961, lr=0.000005
[2023-09-08 13:27:30,838][root][INFO] - Epoch: 0: Step: 321/3680, loss=0.385961, lr=0.000005
[2023-09-08 13:27:37,924][root][INFO] - Epoch: 0: Step: 331/3680, loss=0.839064, lr=0.000005
[2023-09-08 13:27:37,926][root][INFO] - Epoch: 0: Step: 331/3680, loss=0.839064, lr=0.000005
[2023-09-08 13:27:37,926][root][INFO] - Epoch: 0: Step: 331/3680, loss=0.839064, lr=0.000005
[2023-09-08 13:27:37,927][root][INFO] - Epoch: 0: Step: 331/3680, loss=0.839064, lr=0.000005
[2023-09-08 13:27:45,009][root][INFO] - Epoch: 0: Step: 341/3680, loss=0.832827, lr=0.000006
[2023-09-08 13:27:45,010][root][INFO] - Epoch: 0: Step: 341/3680, loss=0.832827, lr=0.000006
[2023-09-08 13:27:45,011][root][INFO] - Epoch: 0: Step: 341/3680, loss=0.832827, lr=0.000006
[2023-09-08 13:27:45,012][root][INFO] - Epoch: 0: Step: 341/3680, loss=0.832827, lr=0.000006
[2023-09-08 13:27:52,131][root][INFO] - Epoch: 0: Step: 351/3680, loss=0.876559, lr=0.000006
[2023-09-08 13:27:52,131][root][INFO] - Epoch: 0: Step: 351/3680, loss=0.876559, lr=0.000006
[2023-09-08 13:27:52,131][root][INFO] - Epoch: 0: Step: 351/3680, loss=0.876559, lr=0.000006
[2023-09-08 13:27:52,145][root][INFO] - Epoch: 0: Step: 351/3680, loss=0.876559, lr=0.000006
[2023-09-08 13:27:59,259][root][INFO] - Epoch: 0: Step: 361/3680, loss=1.174193, lr=0.000006
[2023-09-08 13:27:59,259][root][INFO] - Epoch: 0: Step: 361/3680, loss=1.174193, lr=0.000006
[2023-09-08 13:27:59,260][root][INFO] - Epoch: 0: Step: 361/3680, loss=1.174193, lr=0.000006
[2023-09-08 13:27:59,261][root][INFO] - Epoch: 0: Step: 361/3680, loss=1.174193, lr=0.000006
[2023-09-08 13:28:06,501][root][INFO] - Epoch: 0: Step: 371/3680, loss=0.999442, lr=0.000006
[2023-09-08 13:28:06,504][root][INFO] - Epoch: 0: Step: 371/3680, loss=0.999442, lr=0.000006
[2023-09-08 13:28:06,505][root][INFO] - Epoch: 0: Step: 371/3680, loss=0.999442, lr=0.000006
[2023-09-08 13:28:06,509][root][INFO] - Epoch: 0: Step: 371/3680, loss=0.999442, lr=0.000006
[2023-09-08 13:28:13,688][root][INFO] - Epoch: 0: Step: 381/3680, loss=0.974931, lr=0.000006
[2023-09-08 13:28:13,688][root][INFO] - Epoch: 0: Step: 381/3680, loss=0.974931, lr=0.000006
[2023-09-08 13:28:13,689][root][INFO] - Epoch: 0: Step: 381/3680, loss=0.974931, lr=0.000006
[2023-09-08 13:28:13,708][root][INFO] - Epoch: 0: Step: 381/3680, loss=0.974931, lr=0.000006
[2023-09-08 13:28:20,801][root][INFO] - Epoch: 0: Step: 391/3680, loss=1.026271, lr=0.000006
[2023-09-08 13:28:20,807][root][INFO] - Epoch: 0: Step: 391/3680, loss=1.026271, lr=0.000006
[2023-09-08 13:28:20,808][root][INFO] - Epoch: 0: Step: 391/3680, loss=1.026271, lr=0.000006
[2023-09-08 13:28:20,808][root][INFO] - Epoch: 0: Step: 391/3680, loss=1.026271, lr=0.000006
[2023-09-08 13:28:27,147][root][INFO] - Train batch 400
[2023-09-08 13:28:27,147][root][INFO] - Avg. loss per last 100 batches: 0.689944
[2023-09-08 13:28:27,150][root][INFO] - Train batch 400
[2023-09-08 13:28:27,150][root][INFO] - Avg. loss per last 100 batches: 0.689944
[2023-09-08 13:28:27,153][root][INFO] - Train batch 400
[2023-09-08 13:28:27,154][root][INFO] - Avg. loss per last 100 batches: 0.689944
[2023-09-08 13:28:27,155][root][INFO] - Train batch 400
[2023-09-08 13:28:27,156][root][INFO] - Avg. loss per last 100 batches: 0.689944
[2023-09-08 13:28:27,851][root][INFO] - Epoch: 0: Step: 401/3680, loss=0.155609, lr=0.000006
[2023-09-08 13:28:27,852][root][INFO] - Epoch: 0: Step: 401/3680, loss=0.155609, lr=0.000006
[2023-09-08 13:28:27,855][root][INFO] - Epoch: 0: Step: 401/3680, loss=0.155609, lr=0.000006
[2023-09-08 13:28:27,858][root][INFO] - Epoch: 0: Step: 401/3680, loss=0.155609, lr=0.000006
[2023-09-08 13:28:34,902][root][INFO] - Epoch: 0: Step: 411/3680, loss=0.123054, lr=0.000007
[2023-09-08 13:28:34,904][root][INFO] - Epoch: 0: Step: 411/3680, loss=0.123054, lr=0.000007
[2023-09-08 13:28:34,909][root][INFO] - Epoch: 0: Step: 411/3680, loss=0.123054, lr=0.000007
[2023-09-08 13:28:34,911][root][INFO] - Epoch: 0: Step: 411/3680, loss=0.123054, lr=0.000007
[2023-09-08 13:28:42,060][root][INFO] - Epoch: 0: Step: 421/3680, loss=0.800175, lr=0.000007
[2023-09-08 13:28:42,063][root][INFO] - Epoch: 0: Step: 421/3680, loss=0.800175, lr=0.000007
[2023-09-08 13:28:42,071][root][INFO] - Epoch: 0: Step: 421/3680, loss=0.800175, lr=0.000007
[2023-09-08 13:28:42,087][root][INFO] - Epoch: 0: Step: 421/3680, loss=0.800175, lr=0.000007
[2023-09-08 13:28:49,235][root][INFO] - Epoch: 0: Step: 431/3680, loss=0.112431, lr=0.000007
[2023-09-08 13:28:49,237][root][INFO] - Epoch: 0: Step: 431/3680, loss=0.112431, lr=0.000007
[2023-09-08 13:28:49,245][root][INFO] - Epoch: 0: Step: 431/3680, loss=0.112431, lr=0.000007
[2023-09-08 13:28:49,259][root][INFO] - Epoch: 0: Step: 431/3680, loss=0.112431, lr=0.000007
[2023-09-08 13:28:56,318][root][INFO] - Epoch: 0: Step: 441/3680, loss=0.243002, lr=0.000007
[2023-09-08 13:28:56,321][root][INFO] - Epoch: 0: Step: 441/3680, loss=0.243002, lr=0.000007
[2023-09-08 13:28:56,327][root][INFO] - Epoch: 0: Step: 441/3680, loss=0.243002, lr=0.000007
[2023-09-08 13:28:56,330][root][INFO] - Epoch: 0: Step: 441/3680, loss=0.243002, lr=0.000007
[2023-09-08 13:29:03,361][root][INFO] - Epoch: 0: Step: 451/3680, loss=0.276774, lr=0.000007
[2023-09-08 13:29:03,362][root][INFO] - Epoch: 0: Step: 451/3680, loss=0.276774, lr=0.000007
[2023-09-08 13:29:03,370][root][INFO] - Epoch: 0: Step: 451/3680, loss=0.276774, lr=0.000007
[2023-09-08 13:29:03,370][root][INFO] - Epoch: 0: Step: 451/3680, loss=0.276774, lr=0.000007
[2023-09-08 13:29:10,410][root][INFO] - Epoch: 0: Step: 461/3680, loss=0.518535, lr=0.000007
[2023-09-08 13:29:10,411][root][INFO] - Epoch: 0: Step: 461/3680, loss=0.518535, lr=0.000007
[2023-09-08 13:29:10,416][root][INFO] - Epoch: 0: Step: 461/3680, loss=0.518535, lr=0.000007
[2023-09-08 13:29:10,420][root][INFO] - Epoch: 0: Step: 461/3680, loss=0.518535, lr=0.000007
[2023-09-08 13:29:17,483][root][INFO] - Epoch: 0: Step: 471/3680, loss=1.017636, lr=0.000008
[2023-09-08 13:29:17,486][root][INFO] - Epoch: 0: Step: 471/3680, loss=1.017636, lr=0.000008
[2023-09-08 13:29:17,490][root][INFO] - Epoch: 0: Step: 471/3680, loss=1.017636, lr=0.000008
[2023-09-08 13:29:17,492][root][INFO] - Epoch: 0: Step: 471/3680, loss=1.017636, lr=0.000008
[2023-09-08 13:29:24,722][root][INFO] - Epoch: 0: Step: 481/3680, loss=0.296631, lr=0.000008
[2023-09-08 13:29:24,723][root][INFO] - Epoch: 0: Step: 481/3680, loss=0.296631, lr=0.000008
[2023-09-08 13:29:24,724][root][INFO] - Epoch: 0: Step: 481/3680, loss=0.296631, lr=0.000008
[2023-09-08 13:29:24,727][root][INFO] - Epoch: 0: Step: 481/3680, loss=0.296631, lr=0.000008
[2023-09-08 13:29:31,987][root][INFO] - Epoch: 0: Step: 491/3680, loss=0.166000, lr=0.000008
[2023-09-08 13:29:31,993][root][INFO] - Epoch: 0: Step: 491/3680, loss=0.166000, lr=0.000008
[2023-09-08 13:29:32,008][root][INFO] - Epoch: 0: Step: 491/3680, loss=0.166000, lr=0.000008
[2023-09-08 13:29:32,032][root][INFO] - Epoch: 0: Step: 491/3680, loss=0.166000, lr=0.000008
[2023-09-08 13:29:38,450][root][INFO] - Train batch 500
[2023-09-08 13:29:38,450][root][INFO] - Avg. loss per last 100 batches: 0.442747
[2023-09-08 13:29:38,456][root][INFO] - Train batch 500
[2023-09-08 13:29:38,456][root][INFO] - Avg. loss per last 100 batches: 0.442747
[2023-09-08 13:29:38,457][root][INFO] - Train batch 500
[2023-09-08 13:29:38,457][root][INFO] - Avg. loss per last 100 batches: 0.442747
[2023-09-08 13:29:38,477][root][INFO] - Train batch 500
[2023-09-08 13:29:38,477][root][INFO] - Avg. loss per last 100 batches: 0.442747
[2023-09-08 13:29:39,173][root][INFO] - Epoch: 0: Step: 501/3680, loss=1.270616, lr=0.000008
[2023-09-08 13:29:39,176][root][INFO] - Epoch: 0: Step: 501/3680, loss=1.270616, lr=0.000008
[2023-09-08 13:29:39,180][root][INFO] - Epoch: 0: Step: 501/3680, loss=1.270616, lr=0.000008
[2023-09-08 13:29:39,183][root][INFO] - Epoch: 0: Step: 501/3680, loss=1.270616, lr=0.000008
[2023-09-08 13:29:46,202][root][INFO] - Epoch: 0: Step: 511/3680, loss=0.455987, lr=0.000008
[2023-09-08 13:29:46,205][root][INFO] - Epoch: 0: Step: 511/3680, loss=0.455987, lr=0.000008
[2023-09-08 13:29:46,208][root][INFO] - Epoch: 0: Step: 511/3680, loss=0.455987, lr=0.000008
[2023-09-08 13:29:46,211][root][INFO] - Epoch: 0: Step: 511/3680, loss=0.455987, lr=0.000008
[2023-09-08 13:29:53,256][root][INFO] - Epoch: 0: Step: 521/3680, loss=0.285461, lr=0.000008
[2023-09-08 13:29:53,259][root][INFO] - Epoch: 0: Step: 521/3680, loss=0.285461, lr=0.000008
[2023-09-08 13:29:53,263][root][INFO] - Epoch: 0: Step: 521/3680, loss=0.285461, lr=0.000008
[2023-09-08 13:29:53,267][root][INFO] - Epoch: 0: Step: 521/3680, loss=0.285461, lr=0.000008
[2023-09-08 13:30:00,321][root][INFO] - Epoch: 0: Step: 531/3680, loss=0.870299, lr=0.000009
[2023-09-08 13:30:00,324][root][INFO] - Epoch: 0: Step: 531/3680, loss=0.870299, lr=0.000009
[2023-09-08 13:30:00,330][root][INFO] - Epoch: 0: Step: 531/3680, loss=0.870299, lr=0.000009
[2023-09-08 13:30:00,331][root][INFO] - Epoch: 0: Step: 531/3680, loss=0.870299, lr=0.000009
[2023-09-08 13:30:07,400][root][INFO] - Epoch: 0: Step: 541/3680, loss=0.094626, lr=0.000009
[2023-09-08 13:30:07,404][root][INFO] - Epoch: 0: Step: 541/3680, loss=0.094626, lr=0.000009
[2023-09-08 13:30:07,407][root][INFO] - Epoch: 0: Step: 541/3680, loss=0.094626, lr=0.000009
[2023-09-08 13:30:07,409][root][INFO] - Epoch: 0: Step: 541/3680, loss=0.094626, lr=0.000009
[2023-09-08 13:30:14,518][root][INFO] - Epoch: 0: Step: 551/3680, loss=0.715578, lr=0.000009
[2023-09-08 13:30:14,521][root][INFO] - Epoch: 0: Step: 551/3680, loss=0.715578, lr=0.000009
[2023-09-08 13:30:14,527][root][INFO] - Epoch: 0: Step: 551/3680, loss=0.715578, lr=0.000009
[2023-09-08 13:30:14,527][root][INFO] - Epoch: 0: Step: 551/3680, loss=0.715578, lr=0.000009
[2023-09-08 13:30:21,572][root][INFO] - Epoch: 0: Step: 561/3680, loss=0.255579, lr=0.000009
[2023-09-08 13:30:21,574][root][INFO] - Epoch: 0: Step: 561/3680, loss=0.255579, lr=0.000009
[2023-09-08 13:30:21,583][root][INFO] - Epoch: 0: Step: 561/3680, loss=0.255579, lr=0.000009
[2023-09-08 13:30:21,584][root][INFO] - Epoch: 0: Step: 561/3680, loss=0.255579, lr=0.000009
[2023-09-08 13:30:28,728][root][INFO] - Epoch: 0: Step: 571/3680, loss=0.219690, lr=0.000009
[2023-09-08 13:30:28,737][root][INFO] - Epoch: 0: Step: 571/3680, loss=0.219690, lr=0.000009
[2023-09-08 13:30:28,738][root][INFO] - Epoch: 0: Step: 571/3680, loss=0.219690, lr=0.000009
[2023-09-08 13:30:28,741][root][INFO] - Epoch: 0: Step: 571/3680, loss=0.219690, lr=0.000009
[2023-09-08 13:30:35,823][root][INFO] - Epoch: 0: Step: 581/3680, loss=0.160721, lr=0.000009
[2023-09-08 13:30:35,828][root][INFO] - Epoch: 0: Step: 581/3680, loss=0.160721, lr=0.000009
[2023-09-08 13:30:35,845][root][INFO] - Epoch: 0: Step: 581/3680, loss=0.160721, lr=0.000009
[2023-09-08 13:30:35,848][root][INFO] - Epoch: 0: Step: 581/3680, loss=0.160721, lr=0.000009
[2023-09-08 13:30:43,162][root][INFO] - Epoch: 0: Step: 591/3680, loss=0.846061, lr=0.000010
[2023-09-08 13:30:43,168][root][INFO] - Epoch: 0: Step: 591/3680, loss=0.846061, lr=0.000010
[2023-09-08 13:30:43,172][root][INFO] - Epoch: 0: Step: 591/3680, loss=0.846061, lr=0.000010
[2023-09-08 13:30:43,173][root][INFO] - Epoch: 0: Step: 591/3680, loss=0.846061, lr=0.000010
[2023-09-08 13:30:49,609][root][INFO] - Train batch 600
[2023-09-08 13:30:49,609][root][INFO] - Avg. loss per last 100 batches: 0.403703
[2023-09-08 13:30:49,618][root][INFO] - Train batch 600
[2023-09-08 13:30:49,618][root][INFO] - Avg. loss per last 100 batches: 0.403703
[2023-09-08 13:30:49,619][root][INFO] - Train batch 600
[2023-09-08 13:30:49,619][root][INFO] - Avg. loss per last 100 batches: 0.403703
[2023-09-08 13:30:49,639][root][INFO] - Train batch 600
[2023-09-08 13:30:49,639][root][INFO] - Avg. loss per last 100 batches: 0.403703
[2023-09-08 13:30:50,346][root][INFO] - Epoch: 0: Step: 601/3680, loss=0.106959, lr=0.000010
[2023-09-08 13:30:50,353][root][INFO] - Epoch: 0: Step: 601/3680, loss=0.106959, lr=0.000010
[2023-09-08 13:30:50,355][root][INFO] - Epoch: 0: Step: 601/3680, loss=0.106959, lr=0.000010
[2023-09-08 13:30:50,377][root][INFO] - Epoch: 0: Step: 601/3680, loss=0.106959, lr=0.000010
[2023-09-08 13:30:57,684][root][INFO] - Epoch: 0: Step: 611/3680, loss=0.206357, lr=0.000010
[2023-09-08 13:30:57,692][root][INFO] - Epoch: 0: Step: 611/3680, loss=0.206357, lr=0.000010
[2023-09-08 13:30:57,708][root][INFO] - Epoch: 0: Step: 611/3680, loss=0.206357, lr=0.000010
[2023-09-08 13:30:57,713][root][INFO] - Epoch: 0: Step: 611/3680, loss=0.206357, lr=0.000010
[2023-09-08 13:31:05,021][root][INFO] - Epoch: 0: Step: 621/3680, loss=0.198934, lr=0.000010
[2023-09-08 13:31:05,030][root][INFO] - Epoch: 0: Step: 621/3680, loss=0.198934, lr=0.000010
[2023-09-08 13:31:05,033][root][INFO] - Epoch: 0: Step: 621/3680, loss=0.198934, lr=0.000010
[2023-09-08 13:31:05,056][root][INFO] - Epoch: 0: Step: 621/3680, loss=0.198934, lr=0.000010
[2023-09-08 13:31:12,370][root][INFO] - Epoch: 0: Step: 631/3680, loss=0.067709, lr=0.000010
[2023-09-08 13:31:12,380][root][INFO] - Epoch: 0: Step: 631/3680, loss=0.067709, lr=0.000010
[2023-09-08 13:31:12,382][root][INFO] - Epoch: 0: Step: 631/3680, loss=0.067709, lr=0.000010
[2023-09-08 13:31:12,407][root][INFO] - Epoch: 0: Step: 631/3680, loss=0.067709, lr=0.000010
[2023-09-08 13:31:19,725][root][INFO] - Epoch: 0: Step: 641/3680, loss=0.235066, lr=0.000010
[2023-09-08 13:31:19,734][root][INFO] - Epoch: 0: Step: 641/3680, loss=0.235066, lr=0.000010
[2023-09-08 13:31:19,737][root][INFO] - Epoch: 0: Step: 641/3680, loss=0.235066, lr=0.000010
[2023-09-08 13:31:19,761][root][INFO] - Epoch: 0: Step: 641/3680, loss=0.235066, lr=0.000010
[2023-09-08 13:31:27,048][root][INFO] - Epoch: 0: Step: 651/3680, loss=0.073002, lr=0.000011
[2023-09-08 13:31:27,059][root][INFO] - Epoch: 0: Step: 651/3680, loss=0.073002, lr=0.000011
[2023-09-08 13:31:27,060][root][INFO] - Epoch: 0: Step: 651/3680, loss=0.073002, lr=0.000011
[2023-09-08 13:31:27,084][root][INFO] - Epoch: 0: Step: 651/3680, loss=0.073002, lr=0.000011
[2023-09-08 13:31:34,413][root][INFO] - Epoch: 0: Step: 661/3680, loss=0.294734, lr=0.000011
[2023-09-08 13:31:34,413][root][INFO] - Epoch: 0: Step: 661/3680, loss=0.294734, lr=0.000011
[2023-09-08 13:31:34,425][root][INFO] - Epoch: 0: Step: 661/3680, loss=0.294734, lr=0.000011
[2023-09-08 13:31:34,447][root][INFO] - Epoch: 0: Step: 661/3680, loss=0.294734, lr=0.000011
[2023-09-08 13:31:41,765][root][INFO] - Epoch: 0: Step: 671/3680, loss=0.346044, lr=0.000011
[2023-09-08 13:31:41,766][root][INFO] - Epoch: 0: Step: 671/3680, loss=0.346044, lr=0.000011
[2023-09-08 13:31:41,775][root][INFO] - Epoch: 0: Step: 671/3680, loss=0.346044, lr=0.000011
[2023-09-08 13:31:41,802][root][INFO] - Epoch: 0: Step: 671/3680, loss=0.346044, lr=0.000011
[2023-09-08 13:31:49,079][root][INFO] - Epoch: 0: Step: 681/3680, loss=0.263826, lr=0.000011
[2023-09-08 13:31:49,088][root][INFO] - Epoch: 0: Step: 681/3680, loss=0.263826, lr=0.000011
[2023-09-08 13:31:49,090][root][INFO] - Epoch: 0: Step: 681/3680, loss=0.263826, lr=0.000011
[2023-09-08 13:31:49,115][root][INFO] - Epoch: 0: Step: 681/3680, loss=0.263826, lr=0.000011
[2023-09-08 13:31:56,424][root][INFO] - Epoch: 0: Step: 691/3680, loss=0.425869, lr=0.000011
[2023-09-08 13:31:56,430][root][INFO] - Epoch: 0: Step: 691/3680, loss=0.425869, lr=0.000011
[2023-09-08 13:31:56,433][root][INFO] - Epoch: 0: Step: 691/3680, loss=0.425869, lr=0.000011
[2023-09-08 13:31:56,461][root][INFO] - Epoch: 0: Step: 691/3680, loss=0.425869, lr=0.000011
[2023-09-08 13:32:03,030][root][INFO] - Train batch 700
[2023-09-08 13:32:03,030][root][INFO] - Avg. loss per last 100 batches: 0.291741
[2023-09-08 13:32:03,034][root][INFO] - Train batch 700
[2023-09-08 13:32:03,034][root][INFO] - Avg. loss per last 100 batches: 0.291741
[2023-09-08 13:32:03,041][root][INFO] - Train batch 700
[2023-09-08 13:32:03,041][root][INFO] - Avg. loss per last 100 batches: 0.291741
[2023-09-08 13:32:03,063][root][INFO] - Train batch 700
[2023-09-08 13:32:03,064][root][INFO] - Avg. loss per last 100 batches: 0.291741
[2023-09-08 13:32:03,761][root][INFO] - Epoch: 0: Step: 701/3680, loss=0.220471, lr=0.000011
[2023-09-08 13:32:03,771][root][INFO] - Epoch: 0: Step: 701/3680, loss=0.220471, lr=0.000011
[2023-09-08 13:32:03,771][root][INFO] - Epoch: 0: Step: 701/3680, loss=0.220471, lr=0.000011
[2023-09-08 13:32:03,797][root][INFO] - Epoch: 0: Step: 701/3680, loss=0.220471, lr=0.000011
[2023-09-08 13:32:11,087][root][INFO] - Epoch: 0: Step: 711/3680, loss=0.377250, lr=0.000011
[2023-09-08 13:32:11,095][root][INFO] - Epoch: 0: Step: 711/3680, loss=0.377250, lr=0.000011
[2023-09-08 13:32:11,097][root][INFO] - Epoch: 0: Step: 711/3680, loss=0.377250, lr=0.000011
[2023-09-08 13:32:11,121][root][INFO] - Epoch: 0: Step: 711/3680, loss=0.377250, lr=0.000011
[2023-09-08 13:32:18,428][root][INFO] - Epoch: 0: Step: 721/3680, loss=0.062355, lr=0.000012
[2023-09-08 13:32:18,436][root][INFO] - Epoch: 0: Step: 721/3680, loss=0.062355, lr=0.000012
[2023-09-08 13:32:18,436][root][INFO] - Epoch: 0: Step: 721/3680, loss=0.062355, lr=0.000012
[2023-09-08 13:32:18,459][root][INFO] - Epoch: 0: Step: 721/3680, loss=0.062355, lr=0.000012
[2023-09-08 13:32:25,731][root][INFO] - Epoch: 0: Step: 731/3680, loss=0.191352, lr=0.000012
[2023-09-08 13:32:25,740][root][INFO] - Epoch: 0: Step: 731/3680, loss=0.191352, lr=0.000012
[2023-09-08 13:32:25,743][root][INFO] - Epoch: 0: Step: 731/3680, loss=0.191352, lr=0.000012
[2023-09-08 13:32:25,763][root][INFO] - Epoch: 0: Step: 731/3680, loss=0.191352, lr=0.000012
[2023-09-08 13:32:33,070][root][INFO] - Epoch: 0: Step: 741/3680, loss=0.078884, lr=0.000012
[2023-09-08 13:32:33,078][root][INFO] - Epoch: 0: Step: 741/3680, loss=0.078884, lr=0.000012
[2023-09-08 13:32:33,080][root][INFO] - Epoch: 0: Step: 741/3680, loss=0.078884, lr=0.000012
[2023-09-08 13:32:33,105][root][INFO] - Epoch: 0: Step: 741/3680, loss=0.078884, lr=0.000012
[2023-09-08 13:32:40,424][root][INFO] - Epoch: 0: Step: 751/3680, loss=0.129624, lr=0.000012
[2023-09-08 13:32:40,432][root][INFO] - Epoch: 0: Step: 751/3680, loss=0.129624, lr=0.000012
[2023-09-08 13:32:40,434][root][INFO] - Epoch: 0: Step: 751/3680, loss=0.129624, lr=0.000012
[2023-09-08 13:32:40,457][root][INFO] - Epoch: 0: Step: 751/3680, loss=0.129624, lr=0.000012
[2023-09-08 13:32:47,742][root][INFO] - Epoch: 0: Step: 761/3680, loss=0.617761, lr=0.000012
[2023-09-08 13:32:47,745][root][INFO] - Epoch: 0: Step: 761/3680, loss=0.617761, lr=0.000012
[2023-09-08 13:32:47,750][root][INFO] - Epoch: 0: Step: 761/3680, loss=0.617761, lr=0.000012
[2023-09-08 13:32:47,776][root][INFO] - Epoch: 0: Step: 761/3680, loss=0.617761, lr=0.000012
[2023-09-08 13:32:55,075][root][INFO] - Epoch: 0: Step: 771/3680, loss=0.189610, lr=0.000012
[2023-09-08 13:32:55,077][root][INFO] - Epoch: 0: Step: 771/3680, loss=0.189610, lr=0.000012
[2023-09-08 13:32:55,083][root][INFO] - Epoch: 0: Step: 771/3680, loss=0.189610, lr=0.000012
[2023-09-08 13:32:55,110][root][INFO] - Epoch: 0: Step: 771/3680, loss=0.189610, lr=0.000012
[2023-09-08 13:33:02,385][root][INFO] - Epoch: 0: Step: 781/3680, loss=0.050235, lr=0.000013
[2023-09-08 13:33:02,387][root][INFO] - Epoch: 0: Step: 781/3680, loss=0.050235, lr=0.000013
[2023-09-08 13:33:02,395][root][INFO] - Epoch: 0: Step: 781/3680, loss=0.050235, lr=0.000013
[2023-09-08 13:33:02,418][root][INFO] - Epoch: 0: Step: 781/3680, loss=0.050235, lr=0.000013
[2023-09-08 13:33:09,696][root][INFO] - Epoch: 0: Step: 791/3680, loss=0.258550, lr=0.000013
[2023-09-08 13:33:09,707][root][INFO] - Epoch: 0: Step: 791/3680, loss=0.258550, lr=0.000013
[2023-09-08 13:33:09,709][root][INFO] - Epoch: 0: Step: 791/3680, loss=0.258550, lr=0.000013
[2023-09-08 13:33:09,724][root][INFO] - Epoch: 0: Step: 791/3680, loss=0.258550, lr=0.000013
[2023-09-08 13:33:16,236][root][INFO] - Train batch 800
[2023-09-08 13:33:16,236][root][INFO] - Avg. loss per last 100 batches: 0.328377
[2023-09-08 13:33:16,246][root][INFO] - Train batch 800
[2023-09-08 13:33:16,246][root][INFO] - Avg. loss per last 100 batches: 0.328377
[2023-09-08 13:33:16,246][root][INFO] - Train batch 800
[2023-09-08 13:33:16,247][root][INFO] - Avg. loss per last 100 batches: 0.328377
[2023-09-08 13:33:16,272][root][INFO] - Train batch 800
[2023-09-08 13:33:16,272][root][INFO] - Avg. loss per last 100 batches: 0.328377
[2023-09-08 13:33:16,971][root][INFO] - Epoch: 0: Step: 801/3680, loss=0.364525, lr=0.000013
[2023-09-08 13:33:16,979][root][INFO] - Epoch: 0: Step: 801/3680, loss=0.364525, lr=0.000013
[2023-09-08 13:33:16,981][root][INFO] - Epoch: 0: Step: 801/3680, loss=0.364525, lr=0.000013
[2023-09-08 13:33:17,006][root][INFO] - Epoch: 0: Step: 801/3680, loss=0.364525, lr=0.000013
[2023-09-08 13:33:24,294][root][INFO] - Epoch: 0: Step: 811/3680, loss=0.587033, lr=0.000013
[2023-09-08 13:33:24,302][root][INFO] - Epoch: 0: Step: 811/3680, loss=0.587033, lr=0.000013
[2023-09-08 13:33:24,304][root][INFO] - Epoch: 0: Step: 811/3680, loss=0.587033, lr=0.000013
[2023-09-08 13:33:24,331][root][INFO] - Epoch: 0: Step: 811/3680, loss=0.587033, lr=0.000013
[2023-09-08 13:33:31,605][root][INFO] - Epoch: 0: Step: 821/3680, loss=0.546453, lr=0.000013
[2023-09-08 13:33:31,615][root][INFO] - Epoch: 0: Step: 821/3680, loss=0.546453, lr=0.000013
[2023-09-08 13:33:31,615][root][INFO] - Epoch: 0: Step: 821/3680, loss=0.546453, lr=0.000013
[2023-09-08 13:33:31,641][root][INFO] - Epoch: 0: Step: 821/3680, loss=0.546453, lr=0.000013
[2023-09-08 13:33:38,906][root][INFO] - Epoch: 0: Step: 831/3680, loss=0.500353, lr=0.000013
[2023-09-08 13:33:38,915][root][INFO] - Epoch: 0: Step: 831/3680, loss=0.500353, lr=0.000013
[2023-09-08 13:33:38,916][root][INFO] - Epoch: 0: Step: 831/3680, loss=0.500353, lr=0.000013
[2023-09-08 13:33:38,940][root][INFO] - Epoch: 0: Step: 831/3680, loss=0.500353, lr=0.000013
[2023-09-08 13:33:46,214][root][INFO] - Epoch: 0: Step: 841/3680, loss=0.125826, lr=0.000014
[2023-09-08 13:33:46,214][root][INFO] - Epoch: 0: Step: 841/3680, loss=0.125826, lr=0.000014
[2023-09-08 13:33:46,226][root][INFO] - Epoch: 0: Step: 841/3680, loss=0.125826, lr=0.000014
[2023-09-08 13:33:46,250][root][INFO] - Epoch: 0: Step: 841/3680, loss=0.125826, lr=0.000014
[2023-09-08 13:33:53,545][root][INFO] - Epoch: 0: Step: 851/3680, loss=0.380833, lr=0.000014
[2023-09-08 13:33:53,546][root][INFO] - Epoch: 0: Step: 851/3680, loss=0.380833, lr=0.000014
[2023-09-08 13:33:53,557][root][INFO] - Epoch: 0: Step: 851/3680, loss=0.380833, lr=0.000014
[2023-09-08 13:33:53,578][root][INFO] - Epoch: 0: Step: 851/3680, loss=0.380833, lr=0.000014
[2023-09-08 13:34:00,813][root][INFO] - Epoch: 0: Step: 861/3680, loss=0.241835, lr=0.000014
[2023-09-08 13:34:00,823][root][INFO] - Epoch: 0: Step: 861/3680, loss=0.241835, lr=0.000014
[2023-09-08 13:34:00,824][root][INFO] - Epoch: 0: Step: 861/3680, loss=0.241835, lr=0.000014
[2023-09-08 13:34:00,839][root][INFO] - Epoch: 0: Step: 861/3680, loss=0.241835, lr=0.000014
[2023-09-08 13:34:08,050][root][INFO] - Epoch: 0: Step: 871/3680, loss=0.845548, lr=0.000014
[2023-09-08 13:34:08,060][root][INFO] - Epoch: 0: Step: 871/3680, loss=0.845548, lr=0.000014
[2023-09-08 13:34:08,061][root][INFO] - Epoch: 0: Step: 871/3680, loss=0.845548, lr=0.000014
[2023-09-08 13:34:08,076][root][INFO] - Epoch: 0: Step: 871/3680, loss=0.845548, lr=0.000014
[2023-09-08 13:34:15,292][root][INFO] - Epoch: 0: Step: 881/3680, loss=0.162888, lr=0.000014
[2023-09-08 13:34:15,293][root][INFO] - Epoch: 0: Step: 881/3680, loss=0.162888, lr=0.000014
[2023-09-08 13:34:15,294][root][INFO] - Epoch: 0: Step: 881/3680, loss=0.162888, lr=0.000014
[2023-09-08 13:34:15,309][root][INFO] - Epoch: 0: Step: 881/3680, loss=0.162888, lr=0.000014
[2023-09-08 13:34:22,501][root][INFO] - Epoch: 0: Step: 891/3680, loss=0.318177, lr=0.000014
[2023-09-08 13:34:22,502][root][INFO] - Epoch: 0: Step: 891/3680, loss=0.318177, lr=0.000014
[2023-09-08 13:34:22,503][root][INFO] - Epoch: 0: Step: 891/3680, loss=0.318177, lr=0.000014
[2023-09-08 13:34:22,519][root][INFO] - Epoch: 0: Step: 891/3680, loss=0.318177, lr=0.000014
[2023-09-08 13:34:29,062][root][INFO] - Train batch 900
[2023-09-08 13:34:29,063][root][INFO] - Avg. loss per last 100 batches: 0.288127
[2023-09-08 13:34:29,069][root][INFO] - Train batch 900
[2023-09-08 13:34:29,069][root][INFO] - Avg. loss per last 100 batches: 0.288127
[2023-09-08 13:34:29,071][root][INFO] - Train batch 900
[2023-09-08 13:34:29,071][root][INFO] - Avg. loss per last 100 batches: 0.288127
[2023-09-08 13:34:29,086][root][INFO] - Train batch 900
[2023-09-08 13:34:29,086][root][INFO] - Avg. loss per last 100 batches: 0.288127
[2023-09-08 13:34:29,791][root][INFO] - Epoch: 0: Step: 901/3680, loss=0.109262, lr=0.000015
[2023-09-08 13:34:29,794][root][INFO] - Epoch: 0: Step: 901/3680, loss=0.109262, lr=0.000015
[2023-09-08 13:34:29,811][root][INFO] - Epoch: 0: Step: 901/3680, loss=0.109262, lr=0.000015
[2023-09-08 13:34:29,812][root][INFO] - Epoch: 0: Step: 901/3680, loss=0.109262, lr=0.000015
[2023-09-08 13:34:37,068][root][INFO] - Epoch: 0: Step: 911/3680, loss=0.080394, lr=0.000015
[2023-09-08 13:34:37,069][root][INFO] - Epoch: 0: Step: 911/3680, loss=0.080394, lr=0.000015
[2023-09-08 13:34:37,071][root][INFO] - Epoch: 0: Step: 911/3680, loss=0.080394, lr=0.000015
[2023-09-08 13:34:37,081][root][INFO] - Epoch: 0: Step: 911/3680, loss=0.080394, lr=0.000015
[2023-09-08 13:34:44,272][root][INFO] - Epoch: 0: Step: 921/3680, loss=0.588207, lr=0.000015
[2023-09-08 13:34:44,282][root][INFO] - Epoch: 0: Step: 921/3680, loss=0.588207, lr=0.000015
[2023-09-08 13:34:44,283][root][INFO] - Epoch: 0: Step: 921/3680, loss=0.588207, lr=0.000015
[2023-09-08 13:34:44,298][root][INFO] - Epoch: 0: Step: 921/3680, loss=0.588207, lr=0.000015
[2023-09-08 13:34:51,523][root][INFO] - Epoch: 0: Step: 931/3680, loss=0.403161, lr=0.000015
[2023-09-08 13:34:51,524][root][INFO] - Epoch: 0: Step: 931/3680, loss=0.403161, lr=0.000015
[2023-09-08 13:34:51,526][root][INFO] - Epoch: 0: Step: 931/3680, loss=0.403161, lr=0.000015
[2023-09-08 13:34:51,541][root][INFO] - Epoch: 0: Step: 931/3680, loss=0.403161, lr=0.000015
[2023-09-08 13:34:58,837][root][INFO] - Epoch: 0: Step: 941/3680, loss=0.325315, lr=0.000015
[2023-09-08 13:34:58,842][root][INFO] - Epoch: 0: Step: 941/3680, loss=0.325315, lr=0.000015
[2023-09-08 13:34:58,843][root][INFO] - Epoch: 0: Step: 941/3680, loss=0.325315, lr=0.000015
[2023-09-08 13:34:58,870][root][INFO] - Epoch: 0: Step: 941/3680, loss=0.325315, lr=0.000015
[2023-09-08 13:35:06,155][root][INFO] - Epoch: 0: Step: 951/3680, loss=0.325313, lr=0.000015
[2023-09-08 13:35:06,155][root][INFO] - Epoch: 0: Step: 951/3680, loss=0.325313, lr=0.000015
[2023-09-08 13:35:06,158][root][INFO] - Epoch: 0: Step: 951/3680, loss=0.325313, lr=0.000015
[2023-09-08 13:35:06,181][root][INFO] - Epoch: 0: Step: 951/3680, loss=0.325313, lr=0.000015
[2023-09-08 13:35:13,475][root][INFO] - Epoch: 0: Step: 961/3680, loss=0.052183, lr=0.000016
[2023-09-08 13:35:13,475][root][INFO] - Epoch: 0: Step: 961/3680, loss=0.052183, lr=0.000016
[2023-09-08 13:35:13,478][root][INFO] - Epoch: 0: Step: 961/3680, loss=0.052183, lr=0.000016
[2023-09-08 13:35:13,497][root][INFO] - Epoch: 0: Step: 961/3680, loss=0.052183, lr=0.000016
[2023-09-08 13:35:20,790][root][INFO] - Epoch: 0: Step: 971/3680, loss=0.220591, lr=0.000016
[2023-09-08 13:35:20,790][root][INFO] - Epoch: 0: Step: 971/3680, loss=0.220591, lr=0.000016
[2023-09-08 13:35:20,799][root][INFO] - Epoch: 0: Step: 971/3680, loss=0.220591, lr=0.000016
[2023-09-08 13:35:20,816][root][INFO] - Epoch: 0: Step: 971/3680, loss=0.220591, lr=0.000016
[2023-09-08 13:35:28,102][root][INFO] - Epoch: 0: Step: 981/3680, loss=0.118235, lr=0.000016
[2023-09-08 13:35:28,102][root][INFO] - Epoch: 0: Step: 981/3680, loss=0.118235, lr=0.000016
[2023-09-08 13:35:28,107][root][INFO] - Epoch: 0: Step: 981/3680, loss=0.118235, lr=0.000016
[2023-09-08 13:35:28,128][root][INFO] - Epoch: 0: Step: 981/3680, loss=0.118235, lr=0.000016
[2023-09-08 13:35:35,428][root][INFO] - Epoch: 0: Step: 991/3680, loss=0.286565, lr=0.000016
[2023-09-08 13:35:35,428][root][INFO] - Epoch: 0: Step: 991/3680, loss=0.286565, lr=0.000016
[2023-09-08 13:35:35,430][root][INFO] - Epoch: 0: Step: 991/3680, loss=0.286565, lr=0.000016
[2023-09-08 13:35:35,456][root][INFO] - Epoch: 0: Step: 991/3680, loss=0.286565, lr=0.000016
[2023-09-08 13:35:42,006][root][INFO] - Train batch 1000
[2023-09-08 13:35:42,006][root][INFO] - Avg. loss per last 100 batches: 0.279573
[2023-09-08 13:35:42,011][root][INFO] - Train batch 1000
[2023-09-08 13:35:42,011][root][INFO] - Avg. loss per last 100 batches: 0.279573
[2023-09-08 13:35:42,014][root][INFO] - Train batch 1000
[2023-09-08 13:35:42,014][root][INFO] - Avg. loss per last 100 batches: 0.279573
[2023-09-08 13:35:42,050][root][INFO] - Train batch 1000
[2023-09-08 13:35:42,050][root][INFO] - Avg. loss per last 100 batches: 0.279573
[2023-09-08 13:35:42,763][root][INFO] - Epoch: 0: Step: 1001/3680, loss=0.602812, lr=0.000016
[2023-09-08 13:35:42,765][root][INFO] - Epoch: 0: Step: 1001/3680, loss=0.602812, lr=0.000016
[2023-09-08 13:35:42,768][root][INFO] - Epoch: 0: Step: 1001/3680, loss=0.602812, lr=0.000016
[2023-09-08 13:35:42,793][root][INFO] - Epoch: 0: Step: 1001/3680, loss=0.602812, lr=0.000016
[2023-09-08 13:35:50,048][root][INFO] - Epoch: 0: Step: 1011/3680, loss=0.122270, lr=0.000016
[2023-09-08 13:35:50,054][root][INFO] - Epoch: 0: Step: 1011/3680, loss=0.122270, lr=0.000016
[2023-09-08 13:35:50,055][root][INFO] - Epoch: 0: Step: 1011/3680, loss=0.122270, lr=0.000016
[2023-09-08 13:35:50,055][root][INFO] - Epoch: 0: Step: 1011/3680, loss=0.122270, lr=0.000016
[2023-09-08 13:35:57,064][root][INFO] - Epoch: 0: Step: 1021/3680, loss=0.733101, lr=0.000017
[2023-09-08 13:35:57,069][root][INFO] - Epoch: 0: Step: 1021/3680, loss=0.733101, lr=0.000017
[2023-09-08 13:35:57,073][root][INFO] - Epoch: 0: Step: 1021/3680, loss=0.733101, lr=0.000017
[2023-09-08 13:35:57,073][root][INFO] - Epoch: 0: Step: 1021/3680, loss=0.733101, lr=0.000017
[2023-09-08 13:36:04,193][root][INFO] - Epoch: 0: Step: 1031/3680, loss=0.249664, lr=0.000017
[2023-09-08 13:36:04,199][root][INFO] - Epoch: 0: Step: 1031/3680, loss=0.249664, lr=0.000017
[2023-09-08 13:36:04,199][root][INFO] - Epoch: 0: Step: 1031/3680, loss=0.249664, lr=0.000017
[2023-09-08 13:36:04,199][root][INFO] - Epoch: 0: Step: 1031/3680, loss=0.249664, lr=0.000017
[2023-09-08 13:36:11,296][root][INFO] - Epoch: 0: Step: 1041/3680, loss=0.203136, lr=0.000017
[2023-09-08 13:36:11,298][root][INFO] - Epoch: 0: Step: 1041/3680, loss=0.203136, lr=0.000017
[2023-09-08 13:36:11,298][root][INFO] - Epoch: 0: Step: 1041/3680, loss=0.203136, lr=0.000017
[2023-09-08 13:36:11,299][root][INFO] - Epoch: 0: Step: 1041/3680, loss=0.203136, lr=0.000017
[2023-09-08 13:36:18,397][root][INFO] - Epoch: 0: Step: 1051/3680, loss=0.001358, lr=0.000017
[2023-09-08 13:36:18,400][root][INFO] - Epoch: 0: Step: 1051/3680, loss=0.001358, lr=0.000017
[2023-09-08 13:36:18,400][root][INFO] - Epoch: 0: Step: 1051/3680, loss=0.001358, lr=0.000017
[2023-09-08 13:36:18,410][root][INFO] - Epoch: 0: Step: 1051/3680, loss=0.001358, lr=0.000017
[2023-09-08 13:36:25,523][root][INFO] - Epoch: 0: Step: 1061/3680, loss=0.202758, lr=0.000017
[2023-09-08 13:36:25,525][root][INFO] - Epoch: 0: Step: 1061/3680, loss=0.202758, lr=0.000017
[2023-09-08 13:36:25,532][root][INFO] - Epoch: 0: Step: 1061/3680, loss=0.202758, lr=0.000017
[2023-09-08 13:36:25,547][root][INFO] - Epoch: 0: Step: 1061/3680, loss=0.202758, lr=0.000017
[2023-09-08 13:36:32,654][root][INFO] - Epoch: 0: Step: 1071/3680, loss=0.057516, lr=0.000017
[2023-09-08 13:36:32,659][root][INFO] - Epoch: 0: Step: 1071/3680, loss=0.057516, lr=0.000017
[2023-09-08 13:36:32,660][root][INFO] - Epoch: 0: Step: 1071/3680, loss=0.057516, lr=0.000017
[2023-09-08 13:36:32,678][root][INFO] - Epoch: 0: Step: 1071/3680, loss=0.057516, lr=0.000017
[2023-09-08 13:36:39,764][root][INFO] - Epoch: 0: Step: 1081/3680, loss=0.441364, lr=0.000017
[2023-09-08 13:36:39,765][root][INFO] - Epoch: 0: Step: 1081/3680, loss=0.441364, lr=0.000017
[2023-09-08 13:36:39,765][root][INFO] - Epoch: 0: Step: 1081/3680, loss=0.441364, lr=0.000017
[2023-09-08 13:36:39,781][root][INFO] - Epoch: 0: Step: 1081/3680, loss=0.441364, lr=0.000017
[2023-09-08 13:36:46,841][root][INFO] - Epoch: 0: Step: 1091/3680, loss=0.150482, lr=0.000018
[2023-09-08 13:36:46,842][root][INFO] - Epoch: 0: Step: 1091/3680, loss=0.150482, lr=0.000018
[2023-09-08 13:36:46,843][root][INFO] - Epoch: 0: Step: 1091/3680, loss=0.150482, lr=0.000018
[2023-09-08 13:36:46,843][root][INFO] - Epoch: 0: Step: 1091/3680, loss=0.150482, lr=0.000018
[2023-09-08 13:36:53,182][root][INFO] - Train batch 1100
[2023-09-08 13:36:53,182][root][INFO] - Avg. loss per last 100 batches: 0.272642
[2023-09-08 13:36:53,182][root][INFO] - Train batch 1100
[2023-09-08 13:36:53,182][root][INFO] - Train batch 1100
[2023-09-08 13:36:53,182][root][INFO] - Avg. loss per last 100 batches: 0.272642
[2023-09-08 13:36:53,183][root][INFO] - Avg. loss per last 100 batches: 0.272642
[2023-09-08 13:36:53,185][root][INFO] - Train batch 1100
[2023-09-08 13:36:53,185][root][INFO] - Avg. loss per last 100 batches: 0.272642
[2023-09-08 13:36:53,887][root][INFO] - Epoch: 0: Step: 1101/3680, loss=0.031442, lr=0.000018
[2023-09-08 13:36:53,887][root][INFO] - Epoch: 0: Step: 1101/3680, loss=0.031442, lr=0.000018
[2023-09-08 13:36:53,887][root][INFO] - Epoch: 0: Step: 1101/3680, loss=0.031442, lr=0.000018
[2023-09-08 13:36:53,904][root][INFO] - Epoch: 0: Step: 1101/3680, loss=0.031442, lr=0.000018
[2023-09-08 13:37:00,999][root][INFO] - Epoch: 0: Step: 1111/3680, loss=0.180429, lr=0.000018
[2023-09-08 13:37:00,999][root][INFO] - Epoch: 0: Step: 1111/3680, loss=0.180429, lr=0.000018
[2023-09-08 13:37:01,000][root][INFO] - Epoch: 0: Step: 1111/3680, loss=0.180429, lr=0.000018
[2023-09-08 13:37:01,002][root][INFO] - Epoch: 0: Step: 1111/3680, loss=0.180429, lr=0.000018
[2023-09-08 13:37:08,102][root][INFO] - Epoch: 0: Step: 1121/3680, loss=0.089523, lr=0.000018
[2023-09-08 13:37:08,102][root][INFO] - Epoch: 0: Step: 1121/3680, loss=0.089523, lr=0.000018
[2023-09-08 13:37:08,104][root][INFO] - Epoch: 0: Step: 1121/3680, loss=0.089523, lr=0.000018
[2023-09-08 13:37:08,104][root][INFO] - Epoch: 0: Step: 1121/3680, loss=0.089523, lr=0.000018
[2023-09-08 13:37:15,159][root][INFO] - Epoch: 0: Step: 1131/3680, loss=0.025408, lr=0.000018
[2023-09-08 13:37:15,160][root][INFO] - Epoch: 0: Step: 1131/3680, loss=0.025408, lr=0.000018
[2023-09-08 13:37:15,160][root][INFO] - Epoch: 0: Step: 1131/3680, loss=0.025408, lr=0.000018
[2023-09-08 13:37:15,160][root][INFO] - Epoch: 0: Step: 1131/3680, loss=0.025408, lr=0.000018
[2023-09-08 13:37:22,212][root][INFO] - Epoch: 0: Step: 1141/3680, loss=0.229999, lr=0.000018
[2023-09-08 13:37:22,213][root][INFO] - Epoch: 0: Step: 1141/3680, loss=0.229999, lr=0.000018
[2023-09-08 13:37:22,215][root][INFO] - Epoch: 0: Step: 1141/3680, loss=0.229999, lr=0.000018
[2023-09-08 13:37:22,218][root][INFO] - Epoch: 0: Step: 1141/3680, loss=0.229999, lr=0.000018
[2023-09-08 13:37:29,268][root][INFO] - Epoch: 0: Step: 1151/3680, loss=0.386000, lr=0.000019
[2023-09-08 13:37:29,268][root][INFO] - Epoch: 0: Step: 1151/3680, loss=0.386000, lr=0.000019
[2023-09-08 13:37:29,269][root][INFO] - Epoch: 0: Step: 1151/3680, loss=0.386000, lr=0.000019
[2023-09-08 13:37:29,269][root][INFO] - Epoch: 0: Step: 1151/3680, loss=0.386000, lr=0.000019
[2023-09-08 13:37:36,314][root][INFO] - Epoch: 0: Step: 1161/3680, loss=0.284604, lr=0.000019
[2023-09-08 13:37:36,314][root][INFO] - Epoch: 0: Step: 1161/3680, loss=0.284604, lr=0.000019
[2023-09-08 13:37:36,316][root][INFO] - Epoch: 0: Step: 1161/3680, loss=0.284604, lr=0.000019
[2023-09-08 13:37:36,318][root][INFO] - Epoch: 0: Step: 1161/3680, loss=0.284604, lr=0.000019
[2023-09-08 13:37:43,418][root][INFO] - Epoch: 0: Step: 1171/3680, loss=0.017117, lr=0.000019
[2023-09-08 13:37:43,420][root][INFO] - Epoch: 0: Step: 1171/3680, loss=0.017117, lr=0.000019
[2023-09-08 13:37:43,421][root][INFO] - Epoch: 0: Step: 1171/3680, loss=0.017117, lr=0.000019
[2023-09-08 13:37:43,421][root][INFO] - Epoch: 0: Step: 1171/3680, loss=0.017117, lr=0.000019
[2023-09-08 13:37:50,486][root][INFO] - Epoch: 0: Step: 1181/3680, loss=0.118598, lr=0.000019
[2023-09-08 13:37:50,486][root][INFO] - Epoch: 0: Step: 1181/3680, loss=0.118598, lr=0.000019
[2023-09-08 13:37:50,487][root][INFO] - Epoch: 0: Step: 1181/3680, loss=0.118598, lr=0.000019
[2023-09-08 13:37:50,490][root][INFO] - Epoch: 0: Step: 1181/3680, loss=0.118598, lr=0.000019
[2023-09-08 13:37:57,631][root][INFO] - Epoch: 0: Step: 1191/3680, loss=0.091912, lr=0.000019
[2023-09-08 13:37:57,632][root][INFO] - Epoch: 0: Step: 1191/3680, loss=0.091912, lr=0.000019
[2023-09-08 13:37:57,632][root][INFO] - Epoch: 0: Step: 1191/3680, loss=0.091912, lr=0.000019
[2023-09-08 13:37:57,633][root][INFO] - Epoch: 0: Step: 1191/3680, loss=0.091912, lr=0.000019
[2023-09-08 13:38:04,012][root][INFO] - Train batch 1200
[2023-09-08 13:38:04,012][root][INFO] - Avg. loss per last 100 batches: 0.206731
[2023-09-08 13:38:04,012][root][INFO] - Train batch 1200
[2023-09-08 13:38:04,012][root][INFO] - Avg. loss per last 100 batches: 0.206731
[2023-09-08 13:38:04,014][root][INFO] - Train batch 1200
[2023-09-08 13:38:04,014][root][INFO] - Avg. loss per last 100 batches: 0.206731
[2023-09-08 13:38:04,031][root][INFO] - Train batch 1200
[2023-09-08 13:38:04,031][root][INFO] - Avg. loss per last 100 batches: 0.206731
[2023-09-08 13:38:04,739][root][INFO] - Epoch: 0: Step: 1201/3680, loss=0.341543, lr=0.000019
[2023-09-08 13:38:04,739][root][INFO] - Epoch: 0: Step: 1201/3680, loss=0.341543, lr=0.000019
[2023-09-08 13:38:04,740][root][INFO] - Epoch: 0: Step: 1201/3680, loss=0.341543, lr=0.000019
[2023-09-08 13:38:04,741][root][INFO] - Epoch: 0: Step: 1201/3680, loss=0.341543, lr=0.000019
[2023-09-08 13:38:11,875][root][INFO] - Epoch: 0: Step: 1211/3680, loss=0.112016, lr=0.000020
[2023-09-08 13:38:11,876][root][INFO] - Epoch: 0: Step: 1211/3680, loss=0.112016, lr=0.000020
[2023-09-08 13:38:11,876][root][INFO] - Epoch: 0: Step: 1211/3680, loss=0.112016, lr=0.000020
[2023-09-08 13:38:11,878][root][INFO] - Epoch: 0: Step: 1211/3680, loss=0.112016, lr=0.000020
[2023-09-08 13:38:19,221][root][INFO] - Epoch: 0: Step: 1221/3680, loss=0.127053, lr=0.000020
[2023-09-08 13:38:19,223][root][INFO] - Epoch: 0: Step: 1221/3680, loss=0.127053, lr=0.000020
[2023-09-08 13:38:19,226][root][INFO] - Epoch: 0: Step: 1221/3680, loss=0.127053, lr=0.000020
[2023-09-08 13:38:19,226][root][INFO] - Epoch: 0: Step: 1221/3680, loss=0.127053, lr=0.000020
[2023-09-08 13:38:26,269][root][INFO] - Epoch: 0: Step: 1231/3680, loss=0.039156, lr=0.000020
[2023-09-08 13:38:26,270][root][INFO] - Epoch: 0: Step: 1231/3680, loss=0.039156, lr=0.000020
[2023-09-08 13:38:26,275][root][INFO] - Epoch: 0: Step: 1231/3680, loss=0.039156, lr=0.000020
[2023-09-08 13:38:26,281][root][INFO] - Epoch: 0: Step: 1231/3680, loss=0.039156, lr=0.000020
[2023-09-08 13:38:33,382][root][INFO] - Epoch: 0: Step: 1241/3680, loss=0.526985, lr=0.000020
[2023-09-08 13:38:33,385][root][INFO] - Epoch: 0: Step: 1241/3680, loss=0.526985, lr=0.000020
[2023-09-08 13:38:33,386][root][INFO] - Epoch: 0: Step: 1241/3680, loss=0.526985, lr=0.000020
[2023-09-08 13:38:33,406][root][INFO] - Epoch: 0: Step: 1241/3680, loss=0.526985, lr=0.000020
[2023-09-08 13:38:40,502][root][INFO] - Epoch: 0: Step: 1251/3680, loss=0.307061, lr=0.000020
[2023-09-08 13:38:40,503][root][INFO] - Epoch: 0: Step: 1251/3680, loss=0.307061, lr=0.000020
[2023-09-08 13:38:40,503][root][INFO] - Epoch: 0: Step: 1251/3680, loss=0.307061, lr=0.000020
[2023-09-08 13:38:40,518][root][INFO] - Epoch: 0: Step: 1251/3680, loss=0.307061, lr=0.000020
[2023-09-08 13:38:47,728][root][INFO] - Epoch: 0: Step: 1261/3680, loss=0.276226, lr=0.000020
[2023-09-08 13:38:47,730][root][INFO] - Epoch: 0: Step: 1261/3680, loss=0.276226, lr=0.000020
[2023-09-08 13:38:47,734][root][INFO] - Epoch: 0: Step: 1261/3680, loss=0.276226, lr=0.000020
[2023-09-08 13:38:47,745][root][INFO] - Epoch: 0: Step: 1261/3680, loss=0.276226, lr=0.000020
[2023-09-08 13:38:55,101][root][INFO] - Epoch: 0: Step: 1271/3680, loss=0.067107, lr=0.000020
[2023-09-08 13:38:55,101][root][INFO] - Epoch: 0: Step: 1271/3680, loss=0.067107, lr=0.000020
[2023-09-08 13:38:55,104][root][INFO] - Epoch: 0: Step: 1271/3680, loss=0.067107, lr=0.000020
[2023-09-08 13:38:55,105][root][INFO] - Epoch: 0: Step: 1271/3680, loss=0.067107, lr=0.000020
[2023-09-08 13:39:02,247][root][INFO] - Epoch: 0: Step: 1281/3680, loss=0.123344, lr=0.000020
[2023-09-08 13:39:02,248][root][INFO] - Epoch: 0: Step: 1281/3680, loss=0.123344, lr=0.000020
[2023-09-08 13:39:02,248][root][INFO] - Epoch: 0: Step: 1281/3680, loss=0.123344, lr=0.000020
[2023-09-08 13:39:02,263][root][INFO] - Epoch: 0: Step: 1281/3680, loss=0.123344, lr=0.000020
[2023-09-08 13:39:09,401][root][INFO] - Epoch: 0: Step: 1291/3680, loss=0.241406, lr=0.000020
[2023-09-08 13:39:09,402][root][INFO] - Epoch: 0: Step: 1291/3680, loss=0.241406, lr=0.000020
[2023-09-08 13:39:09,403][root][INFO] - Epoch: 0: Step: 1291/3680, loss=0.241406, lr=0.000020
[2023-09-08 13:39:09,405][root][INFO] - Epoch: 0: Step: 1291/3680, loss=0.241406, lr=0.000020
[2023-09-08 13:39:15,803][root][INFO] - Train batch 1300
[2023-09-08 13:39:15,803][root][INFO] - Avg. loss per last 100 batches: 0.268677
[2023-09-08 13:39:15,805][root][INFO] - Train batch 1300
[2023-09-08 13:39:15,805][root][INFO] - Avg. loss per last 100 batches: 0.268677
[2023-09-08 13:39:15,805][root][INFO] - Train batch 1300
[2023-09-08 13:39:15,805][root][INFO] - Avg. loss per last 100 batches: 0.268677
[2023-09-08 13:39:15,809][root][INFO] - Train batch 1300
[2023-09-08 13:39:15,810][root][INFO] - Avg. loss per last 100 batches: 0.268677
[2023-09-08 13:39:16,514][root][INFO] - Epoch: 0: Step: 1301/3680, loss=0.330300, lr=0.000020
[2023-09-08 13:39:16,517][root][INFO] - Epoch: 0: Step: 1301/3680, loss=0.330300, lr=0.000020
[2023-09-08 13:39:16,517][root][INFO] - Epoch: 0: Step: 1301/3680, loss=0.330300, lr=0.000020
[2023-09-08 13:39:16,519][root][INFO] - Epoch: 0: Step: 1301/3680, loss=0.330300, lr=0.000020
[2023-09-08 13:39:23,736][root][INFO] - Epoch: 0: Step: 1311/3680, loss=0.119360, lr=0.000020
[2023-09-08 13:39:23,741][root][INFO] - Epoch: 0: Step: 1311/3680, loss=0.119360, lr=0.000020
[2023-09-08 13:39:23,741][root][INFO] - Epoch: 0: Step: 1311/3680, loss=0.119360, lr=0.000020
[2023-09-08 13:39:23,753][root][INFO] - Epoch: 0: Step: 1311/3680, loss=0.119360, lr=0.000020
[2023-09-08 13:39:30,903][root][INFO] - Epoch: 0: Step: 1321/3680, loss=0.050387, lr=0.000020
[2023-09-08 13:39:30,905][root][INFO] - Epoch: 0: Step: 1321/3680, loss=0.050387, lr=0.000020
[2023-09-08 13:39:30,906][root][INFO] - Epoch: 0: Step: 1321/3680, loss=0.050387, lr=0.000020
[2023-09-08 13:39:30,907][root][INFO] - Epoch: 0: Step: 1321/3680, loss=0.050387, lr=0.000020
[2023-09-08 13:39:38,203][root][INFO] - Epoch: 0: Step: 1331/3680, loss=0.126316, lr=0.000020
[2023-09-08 13:39:38,208][root][INFO] - Epoch: 0: Step: 1331/3680, loss=0.126316, lr=0.000020
[2023-09-08 13:39:38,211][root][INFO] - Epoch: 0: Step: 1331/3680, loss=0.126316, lr=0.000020
[2023-09-08 13:39:38,229][root][INFO] - Epoch: 0: Step: 1331/3680, loss=0.126316, lr=0.000020
[2023-09-08 13:39:45,331][root][INFO] - Epoch: 0: Step: 1341/3680, loss=0.539497, lr=0.000020
[2023-09-08 13:39:45,341][root][INFO] - Epoch: 0: Step: 1341/3680, loss=0.539497, lr=0.000020
[2023-09-08 13:39:45,342][root][INFO] - Epoch: 0: Step: 1341/3680, loss=0.539497, lr=0.000020
[2023-09-08 13:39:45,343][root][INFO] - Epoch: 0: Step: 1341/3680, loss=0.539497, lr=0.000020
[2023-09-08 13:39:52,609][root][INFO] - Epoch: 0: Step: 1351/3680, loss=0.075215, lr=0.000020
[2023-09-08 13:39:52,617][root][INFO] - Epoch: 0: Step: 1351/3680, loss=0.075215, lr=0.000020
[2023-09-08 13:39:52,618][root][INFO] - Epoch: 0: Step: 1351/3680, loss=0.075215, lr=0.000020
[2023-09-08 13:39:52,623][root][INFO] - Epoch: 0: Step: 1351/3680, loss=0.075215, lr=0.000020
[2023-09-08 13:39:59,666][root][INFO] - Epoch: 0: Step: 1361/3680, loss=0.363165, lr=0.000020
[2023-09-08 13:39:59,675][root][INFO] - Epoch: 0: Step: 1361/3680, loss=0.363165, lr=0.000020
[2023-09-08 13:39:59,676][root][INFO] - Epoch: 0: Step: 1361/3680, loss=0.363165, lr=0.000020
[2023-09-08 13:39:59,677][root][INFO] - Epoch: 0: Step: 1361/3680, loss=0.363165, lr=0.000020
[2023-09-08 13:40:06,909][root][INFO] - Epoch: 0: Step: 1371/3680, loss=0.185298, lr=0.000020
[2023-09-08 13:40:06,914][root][INFO] - Epoch: 0: Step: 1371/3680, loss=0.185298, lr=0.000020
[2023-09-08 13:40:06,915][root][INFO] - Epoch: 0: Step: 1371/3680, loss=0.185298, lr=0.000020
[2023-09-08 13:40:06,916][root][INFO] - Epoch: 0: Step: 1371/3680, loss=0.185298, lr=0.000020
[2023-09-08 13:40:13,973][root][INFO] - Epoch: 0: Step: 1381/3680, loss=0.164153, lr=0.000020
[2023-09-08 13:40:13,983][root][INFO] - Epoch: 0: Step: 1381/3680, loss=0.164153, lr=0.000020
[2023-09-08 13:40:13,983][root][INFO] - Epoch: 0: Step: 1381/3680, loss=0.164153, lr=0.000020
[2023-09-08 13:40:13,985][root][INFO] - Epoch: 0: Step: 1381/3680, loss=0.164153, lr=0.000020
[2023-09-08 13:40:21,041][root][INFO] - Epoch: 0: Step: 1391/3680, loss=0.244812, lr=0.000020
[2023-09-08 13:40:21,048][root][INFO] - Epoch: 0: Step: 1391/3680, loss=0.244812, lr=0.000020
[2023-09-08 13:40:21,049][root][INFO] - Epoch: 0: Step: 1391/3680, loss=0.244812, lr=0.000020
[2023-09-08 13:40:21,051][root][INFO] - Epoch: 0: Step: 1391/3680, loss=0.244812, lr=0.000020
[2023-09-08 13:40:27,435][root][INFO] - Train batch 1400
[2023-09-08 13:40:27,435][root][INFO] - Avg. loss per last 100 batches: 0.251362
[2023-09-08 13:40:27,444][root][INFO] - Train batch 1400
[2023-09-08 13:40:27,444][root][INFO] - Avg. loss per last 100 batches: 0.251362
[2023-09-08 13:40:27,444][root][INFO] - Train batch 1400
[2023-09-08 13:40:27,444][root][INFO] - Avg. loss per last 100 batches: 0.251362
[2023-09-08 13:40:27,463][root][INFO] - Train batch 1400
[2023-09-08 13:40:27,464][root][INFO] - Avg. loss per last 100 batches: 0.251362
[2023-09-08 13:40:28,174][root][INFO] - Epoch: 0: Step: 1401/3680, loss=0.429210, lr=0.000020
[2023-09-08 13:40:28,179][root][INFO] - Epoch: 0: Step: 1401/3680, loss=0.429210, lr=0.000020
[2023-09-08 13:40:28,179][root][INFO] - Epoch: 0: Step: 1401/3680, loss=0.429210, lr=0.000020
[2023-09-08 13:40:28,182][root][INFO] - Epoch: 0: Step: 1401/3680, loss=0.429210, lr=0.000020
[2023-09-08 13:40:35,234][root][INFO] - Epoch: 0: Step: 1411/3680, loss=0.035860, lr=0.000020
[2023-09-08 13:40:35,243][root][INFO] - Epoch: 0: Step: 1411/3680, loss=0.035860, lr=0.000020
[2023-09-08 13:40:35,244][root][INFO] - Epoch: 0: Step: 1411/3680, loss=0.035860, lr=0.000020
[2023-09-08 13:40:35,245][root][INFO] - Epoch: 0: Step: 1411/3680, loss=0.035860, lr=0.000020
[2023-09-08 13:40:42,462][root][INFO] - Epoch: 0: Step: 1421/3680, loss=0.109641, lr=0.000020
[2023-09-08 13:40:42,470][root][INFO] - Epoch: 0: Step: 1421/3680, loss=0.109641, lr=0.000020
[2023-09-08 13:40:42,472][root][INFO] - Epoch: 0: Step: 1421/3680, loss=0.109641, lr=0.000020
[2023-09-08 13:40:42,498][root][INFO] - Epoch: 0: Step: 1421/3680, loss=0.109641, lr=0.000020
[2023-09-08 13:40:49,802][root][INFO] - Epoch: 0: Step: 1431/3680, loss=0.333466, lr=0.000020
[2023-09-08 13:40:49,812][root][INFO] - Epoch: 0: Step: 1431/3680, loss=0.333466, lr=0.000020
[2023-09-08 13:40:49,813][root][INFO] - Epoch: 0: Step: 1431/3680, loss=0.333466, lr=0.000020
[2023-09-08 13:40:49,837][root][INFO] - Epoch: 0: Step: 1431/3680, loss=0.333466, lr=0.000020
[2023-09-08 13:40:57,115][root][INFO] - Epoch: 0: Step: 1441/3680, loss=0.174404, lr=0.000020
[2023-09-08 13:40:57,116][root][INFO] - Epoch: 0: Step: 1441/3680, loss=0.174404, lr=0.000020
[2023-09-08 13:40:57,116][root][INFO] - Epoch: 0: Step: 1441/3680, loss=0.174404, lr=0.000020
[2023-09-08 13:40:57,119][root][INFO] - Epoch: 0: Step: 1441/3680, loss=0.174404, lr=0.000020
[2023-09-08 13:41:04,246][root][INFO] - Epoch: 0: Step: 1451/3680, loss=0.104214, lr=0.000020
[2023-09-08 13:41:04,248][root][INFO] - Epoch: 0: Step: 1451/3680, loss=0.104214, lr=0.000020
[2023-09-08 13:41:04,248][root][INFO] - Epoch: 0: Step: 1451/3680, loss=0.104214, lr=0.000020
[2023-09-08 13:41:04,249][root][INFO] - Epoch: 0: Step: 1451/3680, loss=0.104214, lr=0.000020
[2023-09-08 13:41:11,379][root][INFO] - Epoch: 0: Step: 1461/3680, loss=0.197083, lr=0.000020
[2023-09-08 13:41:11,383][root][INFO] - Epoch: 0: Step: 1461/3680, loss=0.197083, lr=0.000020
[2023-09-08 13:41:11,384][root][INFO] - Epoch: 0: Step: 1461/3680, loss=0.197083, lr=0.000020
[2023-09-08 13:41:11,386][root][INFO] - Epoch: 0: Step: 1461/3680, loss=0.197083, lr=0.000020
[2023-09-08 13:41:18,607][root][INFO] - Epoch: 0: Step: 1471/3680, loss=0.135065, lr=0.000020
[2023-09-08 13:41:18,608][root][INFO] - Epoch: 0: Step: 1471/3680, loss=0.135065, lr=0.000020
[2023-09-08 13:41:18,610][root][INFO] - Epoch: 0: Step: 1471/3680, loss=0.135065, lr=0.000020
[2023-09-08 13:41:18,636][root][INFO] - Epoch: 0: Step: 1471/3680, loss=0.135065, lr=0.000020
[2023-09-08 13:41:25,962][root][INFO] - Epoch: 0: Step: 1481/3680, loss=0.118766, lr=0.000020
[2023-09-08 13:41:25,964][root][INFO] - Epoch: 0: Step: 1481/3680, loss=0.118766, lr=0.000020
[2023-09-08 13:41:25,964][root][INFO] - Epoch: 0: Step: 1481/3680, loss=0.118766, lr=0.000020
[2023-09-08 13:41:25,989][root][INFO] - Epoch: 0: Step: 1481/3680, loss=0.118766, lr=0.000020
[2023-09-08 13:41:33,270][root][INFO] - Epoch: 0: Step: 1491/3680, loss=0.130361, lr=0.000020
[2023-09-08 13:41:33,270][root][INFO] - Epoch: 0: Step: 1491/3680, loss=0.130361, lr=0.000020
[2023-09-08 13:41:33,273][root][INFO] - Epoch: 0: Step: 1491/3680, loss=0.130361, lr=0.000020
[2023-09-08 13:41:33,298][root][INFO] - Epoch: 0: Step: 1491/3680, loss=0.130361, lr=0.000020
[2023-09-08 13:41:39,870][root][INFO] - Train batch 1500
[2023-09-08 13:41:39,871][root][INFO] - Avg. loss per last 100 batches: 0.252821
[2023-09-08 13:41:39,871][root][INFO] - Train batch 1500
[2023-09-08 13:41:39,872][root][INFO] - Avg. loss per last 100 batches: 0.252821
[2023-09-08 13:41:39,872][root][INFO] - Train batch 1500
[2023-09-08 13:41:39,872][root][INFO] - Avg. loss per last 100 batches: 0.252821
[2023-09-08 13:41:39,893][root][INFO] - Train batch 1500
[2023-09-08 13:41:39,894][root][INFO] - Avg. loss per last 100 batches: 0.252821
[2023-09-08 13:41:40,598][root][INFO] - Epoch: 0: Step: 1501/3680, loss=0.354558, lr=0.000020
[2023-09-08 13:41:40,600][root][INFO] - Epoch: 0: Step: 1501/3680, loss=0.354558, lr=0.000020
[2023-09-08 13:41:40,600][root][INFO] - Epoch: 0: Step: 1501/3680, loss=0.354558, lr=0.000020
[2023-09-08 13:41:40,623][root][INFO] - Epoch: 0: Step: 1501/3680, loss=0.354558, lr=0.000020
[2023-09-08 13:41:47,939][root][INFO] - Epoch: 0: Step: 1511/3680, loss=0.545091, lr=0.000020
[2023-09-08 13:41:47,939][root][INFO] - Epoch: 0: Step: 1511/3680, loss=0.545091, lr=0.000020
[2023-09-08 13:41:47,940][root][INFO] - Epoch: 0: Step: 1511/3680, loss=0.545091, lr=0.000020
[2023-09-08 13:41:47,965][root][INFO] - Epoch: 0: Step: 1511/3680, loss=0.545091, lr=0.000020
[2023-09-08 13:41:55,256][root][INFO] - Epoch: 0: Step: 1521/3680, loss=0.059885, lr=0.000020
[2023-09-08 13:41:55,256][root][INFO] - Epoch: 0: Step: 1521/3680, loss=0.059885, lr=0.000020
[2023-09-08 13:41:55,257][root][INFO] - Epoch: 0: Step: 1521/3680, loss=0.059885, lr=0.000020
[2023-09-08 13:41:55,278][root][INFO] - Epoch: 0: Step: 1521/3680, loss=0.059885, lr=0.000020
